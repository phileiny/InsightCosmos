# InsightCosmos ä½¿ç”¨æ‰‹å†Š

> **ç‰ˆæœ¬**: 1.1.0
> **æœ€å¾Œæ›´æ–°**: 2025-11-26
> **é©ç”¨éšæ®µ**: Phase 1 - å€‹äººå®‡å®™ç‰ˆï¼ˆå®Œæ•´ç‰ˆï¼‰

[English](USER_MANUAL.md) | **ç¹é«”ä¸­æ–‡**

---

## ğŸ“š ç›®éŒ„

1. [å¿«é€Ÿé–‹å§‹](#å¿«é€Ÿé–‹å§‹)
2. [æ—¥å ±èˆ‡é€±å ±](#æ—¥å ±èˆ‡é€±å ±)
3. [å€‹äººåŒ–é…ç½®](#å€‹äººåŒ–é…ç½®)
4. [è³‡æ–™ç®¡ç†](#è³‡æ–™ç®¡ç†)
5. [é€²éšè¨­å®š](#é€²éšè¨­å®š)
6. [éƒ¨ç½²æŒ‡å—](#éƒ¨ç½²æŒ‡å—)
7. [å‚™ä»½èˆ‡é‚„åŸ](#å‚™ä»½èˆ‡é‚„åŸ)
8. [å¸¸è¦‹å•é¡Œ](#å¸¸è¦‹å•é¡Œ)
9. [æ•…éšœæ’é™¤](#æ•…éšœæ’é™¤)

---

## ğŸš€ å¿«é€Ÿé–‹å§‹

### ç³»çµ±éœ€æ±‚

- Python 3.10+ï¼ˆå»ºè­° 3.11 æˆ– 3.13ï¼‰
- è‡³å°‘ 4GB RAM
- ç©©å®šçš„ç¶²è·¯é€£ç·š
- Google Gemini API Key

### åˆæ¬¡å®‰è£

```bash
# 1. Clone å°ˆæ¡ˆ
git clone https://github.com/your-repo/InsightCosmos.git
cd InsightCosmos

# 2. å‰µå»ºè™›æ“¬ç’°å¢ƒ
python -m venv venv
source venv/bin/activate  # Linux/Mac
# æˆ– venv\Scripts\activate  # Windows

# 3. å®‰è£ä¾è³´
pip install -r requirements.txt

# 4. é…ç½®ç’°å¢ƒè®Šæ•¸
cp .env.example .env
# ç·¨è¼¯ .env å¡«å…¥ä½ çš„é…ç½®ï¼ˆè¦‹ä¸‹æ–¹è©³ç´°èªªæ˜ï¼‰

# 5. åˆå§‹åŒ–è³‡æ–™åº«
python -m src.memory.database

# 6. æ¸¬è©¦é‹è¡Œï¼ˆä¸ç™¼é€éƒµä»¶ï¼‰
python -m src.orchestrator.daily_runner --dry-run
```

### ç’°å¢ƒè®Šæ•¸é…ç½®ï¼ˆ.envï¼‰

```bash
# Google Gemini API (å¿…éœ€)
# å¾ https://aistudio.google.com/apikey å–å¾—
GOOGLE_API_KEY=your_gemini_api_key

# Email é…ç½® (å¿…éœ€)
EMAIL_ACCOUNT=your_email@gmail.com
EMAIL_PASSWORD=your_app_password  # ä½¿ç”¨ Gmail App Password

# SMTP è¨­å®šï¼ˆå¯é¸ï¼Œé è¨­ Gmailï¼‰
SMTP_HOST=smtp.gmail.com
SMTP_PORT=587
SMTP_USE_TLS=true

# è³‡æ–™åº«ï¼ˆå¯é¸ï¼Œé è¨­ data/insights.dbï¼‰
DATABASE_PATH=data/insights.db

# å€‹äººé…ç½®
USER_NAME=Ray
USER_INTERESTS=AI,Robotics,Multi-Agent Systems

# æ—¥èªŒç´šåˆ¥ï¼ˆDEBUG, INFO, WARNING, ERRORï¼‰
LOG_LEVEL=INFO
```

### Gmail App Password è¨­å®š

1. å‰å¾€ [Google å¸³æˆ¶å®‰å…¨æ€§è¨­å®š](https://myaccount.google.com/security)
2. å•Ÿç”¨ã€Œå…©æ­¥é©Ÿé©—è­‰ã€
3. åœ¨ã€Œå…©æ­¥é©Ÿé©—è­‰ã€é é¢åº•éƒ¨ï¼Œé»æ“Šã€Œæ‡‰ç”¨ç¨‹å¼å¯†ç¢¼ã€
4. é¸æ“‡ã€Œéƒµä»¶ã€å’Œä½ çš„è£ç½®
5. ç”Ÿæˆå¯†ç¢¼ä¸¦è¤‡è£½åˆ° `.env` çš„ `EMAIL_PASSWORD`

---

## ğŸ“¬ æ—¥å ±èˆ‡é€±å ±

### Daily Pipelineï¼ˆæ¯æ—¥æƒ…å ±ï¼‰

æ¯æ—¥ Pipeline åŸ·è¡Œä¸‰å€‹éšæ®µï¼š
1. **Scout Agent**: å¾ RSS å’Œ Google Search æ”¶é›†æ–‡ç« 
2. **Analyst Agent**: ä½¿ç”¨ LLM åˆ†ææ–‡ç« ã€è©•åˆ†ã€æå–æ´å¯Ÿ
3. **Curator Agent**: ç”Ÿæˆä¸¦ç™¼é€æ¯æ—¥æ‘˜è¦éƒµä»¶

#### åŸ·è¡Œå‘½ä»¤

```bash
# å•Ÿç”¨è™›æ“¬ç’°å¢ƒ
source venv/bin/activate

# ç”Ÿç”¢æ¨¡å¼ï¼ˆæ”¶é›† + åˆ†æ + ç™¼é€éƒµä»¶ï¼‰
python -m src.orchestrator.daily_runner

# æ¸¬è©¦æ¨¡å¼ï¼ˆä¸ç™¼é€éƒµä»¶ï¼ŒæŸ¥çœ‹å ±å‘Šå…§å®¹ï¼‰
python -m src.orchestrator.daily_runner --dry-run

# è©³ç´°æ—¥èªŒæ¨¡å¼ï¼ˆç”¨æ–¼èª¿è©¦ï¼‰
python -m src.orchestrator.daily_runner --verbose

# çµ„åˆä½¿ç”¨
python -m src.orchestrator.daily_runner --dry-run --verbose
```

#### åŸ·è¡Œæ™‚é–“

| éšæ®µ | é ä¼°æ™‚é–“ |
|------|----------|
| Scout (æ”¶é›†) | 30-60 ç§’ |
| Analyst (åˆ†æ) | 1-3 åˆ†é˜ |
| Curator (å ±å‘Š) | 10-30 ç§’ |
| **ç¸½è¨ˆ** | **2-5 åˆ†é˜** |

### Weekly Pipelineï¼ˆé€±å ±è¶¨å‹¢ï¼‰

é€±å ± Pipeline åˆ†æä¸€é€±çš„æ–‡ç« ï¼Œé€²è¡Œä¸»é¡Œèšé¡å’Œè¶¨å‹¢è­˜åˆ¥ï¼š
1. æŸ¥è©¢ä¸€é€±å…§å·²åˆ†æçš„é«˜å„ªå…ˆåº¦æ–‡ç« 
2. ä½¿ç”¨å‘é‡èšé¡è­˜åˆ¥ä¸»é¡Œç¾¤
3. åˆ†æç†±é–€è¶¨å‹¢å’Œæ–°èˆˆè©±é¡Œ
4. ä½¿ç”¨ LLM ç”Ÿæˆé€±å ±
5. ç™¼é€é€±å ±éƒµä»¶

#### åŸ·è¡Œå‘½ä»¤

```bash
# å•Ÿç”¨è™›æ“¬ç’°å¢ƒ
source venv/bin/activate

# ç”Ÿç”¢æ¨¡å¼ï¼ˆåˆ†æ + ç™¼é€éƒµä»¶ï¼‰
python -m src.orchestrator.weekly_runner

# æ¸¬è©¦æ¨¡å¼ï¼ˆä¸ç™¼é€éƒµä»¶ï¼‰
python -m src.orchestrator.weekly_runner --dry-run

# è©³ç´°æ—¥èªŒæ¨¡å¼
python -m src.orchestrator.weekly_runner --verbose

# æŒ‡å®šæ—¥æœŸç¯„åœ
python -m src.orchestrator.weekly_runner --week-start 2025-11-18 --week-end 2025-11-24

# çµ„åˆä½¿ç”¨
python -m src.orchestrator.weekly_runner --dry-run --verbose
```

#### é€±å ±è¼¸å‡ºå…§å®¹

| é …ç›® | èªªæ˜ |
|------|------|
| ä¸»é¡Œç¾¤é›† | å°‡æ–‡ç« æŒ‰ç›¸ä¼¼åº¦åˆ†æˆ 3-7 å€‹ä¸»é¡Œç¾¤ |
| ç†±é–€è¶¨å‹¢ | å‡ºç¾é »ç‡é«˜ã€å„ªå…ˆåº¦é«˜çš„é—œéµå­— |
| æ–°èˆˆè©±é¡Œ | ä½é »ä½†é«˜å„ªå…ˆåº¦çš„æ–°èˆˆé—œéµå­— |
| é€±å ±æ‘˜è¦ | LLM ç”Ÿæˆçš„é€±åº¦ç¸½çµå ±å‘Š |

#### åŸ·è¡Œæ™‚é–“

| éšæ®µ | é ä¼°æ™‚é–“ |
|------|----------|
| è³‡æ–™æŸ¥è©¢ | < 1 ç§’ |
| å‘é‡èšé¡ | 1-2 ç§’ |
| è¶¨å‹¢åˆ†æ | < 1 ç§’ |
| LLM å ±å‘Š | 10-15 ç§’ |
| éƒµä»¶ç™¼é€ | 2-3 ç§’ |
| **ç¸½è¨ˆ** | **15-20 ç§’** |

### è‡ªå‹•åŒ–æ’ç¨‹

#### Linux/Mac (Cron)

```bash
# ç·¨è¼¯ crontab
crontab -e

# æ¯å¤©æ—©ä¸Š 8 é»åŸ·è¡Œæ—¥å ±
0 8 * * * cd /path/to/InsightCosmos && /path/to/venv/bin/python -m src.orchestrator.daily_runner >> /path/to/logs/daily_$(date +\%Y\%m\%d).log 2>&1

# æ¯é€±æ—¥æ™šä¸Š 8 é»åŸ·è¡Œé€±å ±
0 20 * * 0 cd /path/to/InsightCosmos && /path/to/venv/bin/python -m src.orchestrator.weekly_runner >> /path/to/logs/weekly_$(date +\%Y\%m\%d).log 2>&1
```

#### å®Œæ•´ç¯„ä¾‹ï¼ˆå«æ—¥èªŒè¼ªæ›¿ï¼‰

```bash
# æ¯å¤©æ—©ä¸Š 8 é»åŸ·è¡Œæ—¥å ±
0 8 * * * cd /Users/ray/sides/InsightCosmos && /Users/ray/sides/InsightCosmos/venv/bin/python -m src.orchestrator.daily_runner >> /Users/ray/sides/InsightCosmos/logs/daily_$(date +\%Y\%m\%d).log 2>&1

# æ¯é€±æ—¥æ™šä¸Š 8 é»åŸ·è¡Œé€±å ±
0 20 * * 0 cd /Users/ray/sides/InsightCosmos && /Users/ray/sides/InsightCosmos/venv/bin/python -m src.orchestrator.weekly_runner >> /Users/ray/sides/InsightCosmos/logs/weekly_$(date +\%Y\%m\%d).log 2>&1

# æ¯æœˆ 1 è™Ÿæ¸…ç† 90 å¤©å‰çš„è³‡æ–™
0 0 1 * * cd /Users/ray/sides/InsightCosmos && /Users/ray/sides/InsightCosmos/venv/bin/python scripts/cleanup_old_data.py --days 90 >> /Users/ray/sides/InsightCosmos/logs/cleanup.log 2>&1
```

#### Windows Task Scheduler

1. é–‹å•Ÿ Task Scheduler
2. å‰µå»ºåŸºæœ¬ä»»å‹™
3. è¨­å®šè§¸ç™¼å™¨ï¼ˆæ¯å¤©æ—©ä¸Š 8 é»ï¼‰
4. è¨­å®šå‹•ä½œï¼š
   - **Program**: `C:\path\to\InsightCosmos\venv\Scripts\python.exe`
   - **Arguments**: `-m src.orchestrator.daily_runner`
   - **Start in**: `C:\path\to\InsightCosmos`
5. å®Œæˆ

---

## ğŸ¯ å€‹äººåŒ–é…ç½®

### 1. ä¿®æ”¹é—œæ³¨é ˜åŸŸèˆ‡ä¸»é¡Œ

ç·¨è¼¯ `.env` æª”æ¡ˆä¸­çš„ `USER_INTERESTS` è®Šæ•¸ï¼š

```bash
# .env

# åŸºç¤è¨­å®š
USER_NAME=Ray
USER_INTERESTS=AI,Robotics,Multi-Agent Systems

# è‡ªè¨‚ä½ çš„é—œæ³¨é ˜åŸŸï¼ˆç”¨é€—è™Ÿåˆ†éš”ï¼‰
# ç¯„ä¾‹ 1: æ›´å»£æ³›çš„é ˜åŸŸ
USER_INTERESTS=AI,Machine Learning,Computer Vision,NLP,Robotics,Autonomous Systems

# ç¯„ä¾‹ 2: æ›´å°ˆæ³¨çš„é ˜åŸŸ
USER_INTERESTS=Large Language Models,Prompt Engineering,AI Agents,RAG

# ç¯„ä¾‹ 3: è·¨é ˜åŸŸ
USER_INTERESTS=AI,Healthcare,Drug Discovery,Medical Imaging

# ç¯„ä¾‹ 4: æŠ€è¡“ + å•†æ¥­
USER_INTERESTS=AI,Startups,Venture Capital,Product Management
```

### 2. èª¿æ•´ RSS è³‡æ–™ä¾†æº

ç·¨è¼¯ `src/agents/scout_agent.py`ï¼Œä¿®æ”¹ `DEFAULT_FEEDS` åˆ—è¡¨ï¼š

```python
# src/agents/scout_agent.py

DEFAULT_FEEDS = [
    # ç¾æœ‰ä¾†æº
    "https://feeds.feedburner.com/blogspot/gJZg",  # Google AI Blog
    "https://openai.com/blog/rss",                  # OpenAI Blog
    "https://www.deepmind.com/blog/rss.xml",        # DeepMind Blog

    # æ–°å¢ä½ çš„è‡ªè¨‚ä¾†æº
    "https://huggingface.co/blog/feed.xml",         # Hugging Face Blog
    "https://blog.research.google/feeds/posts/default", # Google Research
    "https://arxiv-sanity-lite.com/rss",            # ArXiv ML Papers
    "https://www.reddit.com/r/MachineLearning/.rss", # Reddit ML
    "https://news.ycombinator.com/rss",             # Hacker News

    # è¡Œæ¥­åª’é«”
    "https://venturebeat.com/category/ai/feed/",    # VentureBeat AI
    "https://techcrunch.com/category/artificial-intelligence/feed/", # TechCrunch AI
]
```

**æç¤º**:
- ä½¿ç”¨ [RSS.app](https://rss.app/) å°‡ä»»ä½•ç¶²ç«™è½‰æ›ç‚º RSS feed
- ä½¿ç”¨ [Feedly](https://feedly.com/) ç™¼ç¾æ›´å¤šé«˜å“è³ª RSS ä¾†æº
- ç¢ºä¿ RSS feed URL æœ‰æ•ˆï¼ˆå¯ç”¨ç€è¦½å™¨æ¸¬è©¦ï¼‰

### 3. èª¿æ•´æœç´¢é—œéµå­—

ç·¨è¼¯ `src/agents/scout_agent.py`ï¼Œä¿®æ”¹ `DEFAULT_SEARCH_QUERIES`ï¼š

```python
# src/agents/scout_agent.py

DEFAULT_SEARCH_QUERIES = [
    # ç¾æœ‰é—œéµå­—
    "AI breakthrough OR AGI OR artificial general intelligence",
    "OpenAI OR Anthropic OR Google AI latest",
    "multimodal AI OR vision language model",

    # æ–°å¢ä½ çš„è‡ªè¨‚é—œéµå­—
    # æŠ€è¡“æ–¹å‘
    "retrieval augmented generation RAG",
    "prompt engineering best practices",
    "AI agent framework OR autonomous agents",

    # æ‡‰ç”¨å ´æ™¯
    "AI in healthcare OR medical AI",
    "robotics manipulation OR robot learning",
    "self-driving OR autonomous vehicles",

    # å•†æ¥­èˆ‡è¶¨å‹¢
    "AI startup funding OR AI investment",
    "AI regulation OR AI policy",
    "AGI safety OR AI alignment",

    # ç ”ç©¶å‰æ²¿
    "transformer architecture OR attention mechanism",
    "reinforcement learning from human feedback RLHF",
    "mixture of experts MoE",
]
```

**æœç´¢æŠ€å·§**:
- ä½¿ç”¨ `OR` é€£æ¥åŒç¾©è©: `"AGI OR artificial general intelligence"`
- ä½¿ç”¨å¼•è™Ÿç²¾ç¢ºåŒ¹é…: `"large language model"`
- ä½¿ç”¨ `-` æ’é™¤é—œéµå­—: `"AI -cryptocurrency"`
- é™åˆ¶æ™‚é–“ç¯„åœ: åœ¨ search queries åŠ ä¸Š `after:2025-01-01`

### 4. èª¿æ•´å…§å®¹å„ªå…ˆåº¦æ¼”ç®—æ³•

ç·¨è¼¯ `prompts/analyst_prompt.txt`ï¼Œèª¿æ•´è©•åˆ†æ¨™æº–ï¼š

```
ä½ çš„è©•åˆ†æ¨™æº–ï¼ˆ0.0-1.0ï¼‰ï¼š

**é«˜å„ªå…ˆåº¦ (0.8-1.0)**ï¼š
- æŠ€è¡“çªç ´ï¼ˆæ–°æ¨¡å‹ã€æ–°æ¶æ§‹ã€æ–°ç†è«–ï¼‰
- èˆ‡ {user_interests} é«˜åº¦ç›¸é—œ
- æœ‰å¯¦éš›æ‡‰ç”¨åƒ¹å€¼æˆ–ç¨‹å¼ç¢¼
- ä¾†è‡ªé ‚ç´šç ”ç©¶æ©Ÿæ§‹æˆ–å…¬å¸
- æœ‰è©³ç´°æŠ€è¡“ç´°ç¯€æˆ–è«–æ–‡é€£çµ

**ä¸­å„ªå…ˆåº¦ (0.5-0.7)**ï¼š
- è¡Œæ¥­è¶¨å‹¢åˆ†æ
- æ‡‰ç”¨æ¡ˆä¾‹åˆ†äº«
- å·¥å…·æˆ–æ¡†æ¶ç™¼å¸ƒ
- ç›¸é—œä½†éæ ¸å¿ƒé ˜åŸŸ

**ä½å„ªå…ˆåº¦ (0.0-0.4)**ï¼š
- æ–°èå ±å°æˆ–å…¬é—œç¨¿
- èˆ‡ {user_interests} ä¸ç›¸é—œ
- ç¼ºä¹æŠ€è¡“æ·±åº¦
- éæ™‚æˆ–é‡è¤‡å…§å®¹
```

ä½ å¯ä»¥æ ¹æ“šè‡ªå·±çš„éœ€æ±‚èª¿æ•´é€™äº›æ¨™æº–ã€‚ä¾‹å¦‚ï¼š

- **å­¸è¡“å°å‘**: æé«˜è«–æ–‡æ¬Šé‡ï¼Œé™ä½æ–°èå ±å°æ¬Šé‡
- **å•†æ¥­å°å‘**: æé«˜ç”¢å“ç™¼å¸ƒã€èè³‡æ–°èæ¬Šé‡
- **å·¥ç¨‹å°å‘**: æé«˜é–‹æºå·¥å…·ã€ç¨‹å¼ç¢¼ç¯„ä¾‹æ¬Šé‡

---

## ğŸ“§ å¤šäººéƒµä»¶é…ç½®

### æ–¹æ³• 1: ä¿®æ”¹ Curator Agentï¼ˆå–®æ¬¡ç™¼é€å¤šäººï¼‰

ç·¨è¼¯ `src/agents/curator_daily.py`ï¼Œä¿®æ”¹æ”¶ä»¶äººåˆ—è¡¨ï¼š

```python
# src/agents/curator_daily.py

def generate_daily_digest(
    config: Config,
    recipient_email: str = None,  # å–®ä¸€æ”¶ä»¶äººï¼ˆä¿ç•™å‘å¾Œå…¼å®¹ï¼‰
    recipient_emails: List[str] = None,  # æ–°å¢ï¼šå¤šå€‹æ”¶ä»¶äºº
    max_articles: int = 10
) -> Dict[str, Any]:
    """
    ç”Ÿæˆä¸¦ç™¼é€æ¯æ—¥æƒ…å ±æ‘˜è¦

    Args:
        config: é…ç½®å°è±¡
        recipient_email: å–®ä¸€æ”¶ä»¶äººï¼ˆå·²æ£„ç”¨ï¼‰
        recipient_emails: æ”¶ä»¶äººåˆ—è¡¨ï¼ˆæ¨è–¦ï¼‰
        max_articles: æœ€å¤šåŒ…å«æ–‡ç« æ•¸
    """

    # å‘å¾Œå…¼å®¹ï¼šå¦‚æœåªæä¾›å–®ä¸€æ”¶ä»¶äºº
    if recipient_emails is None:
        if recipient_email:
            recipient_emails = [recipient_email]
        else:
            recipient_emails = [config.email_account]

    # ç”Ÿæˆéƒµä»¶å…§å®¹ï¼ˆåŒå‰ï¼‰
    html_body = formatter.format_digest(...)
    text_body = formatter.format_digest_text(...)

    # ç™¼é€çµ¦å¤šå€‹æ”¶ä»¶äºº
    results = []
    for email in recipient_emails:
        result = sender.send(
            to_email=email,
            subject=f"InsightCosmos Daily Digest - {today_str}",
            html_body=html_body,
            text_body=text_body
        )
        results.append({
            "email": email,
            "status": result["status"]
        })

    return {
        "status": "success" if all(r["status"] == "success" for r in results) else "partial",
        "recipients": results,
        "total_sent": sum(1 for r in results if r["status"] == "success"),
        "total_failed": sum(1 for r in results if r["status"] != "success")
    }
```

### æ–¹æ³• 2: ä½¿ç”¨ç’°å¢ƒè®Šæ•¸é…ç½®å¤šå€‹æ”¶ä»¶äºº

ç·¨è¼¯ `.env` æª”æ¡ˆï¼š

```bash
# .env

# ä¸»è¦æ”¶ä»¶äººï¼ˆä½ è‡ªå·±ï¼‰
EMAIL_ACCOUNT=your_email@gmail.com

# é¡å¤–æ”¶ä»¶äººåˆ—è¡¨ï¼ˆç”¨é€—è™Ÿåˆ†éš”ï¼‰
ADDITIONAL_RECIPIENTS=colleague1@example.com,colleague2@example.com,team@company.com

# æˆ–ä½¿ç”¨ CC/BCC
EMAIL_CC=colleague@example.com
EMAIL_BCC=archive@company.com
```

### æ–¹æ³• 3: åœ˜éšŠå…±ç”¨éƒµä»¶åˆ—è¡¨

ä½¿ç”¨éƒµä»¶æœå‹™å•†çš„éƒµä»¶åˆ—è¡¨åŠŸèƒ½ï¼š

1. **Gmail**: å‰µå»º Google Group
   - è¨ªå• [groups.google.com](https://groups.google.com)
   - å‰µå»ºç¾¤çµ„ï¼ˆä¾‹å¦‚ï¼š`insightcosmos-team@googlegroups.com`ï¼‰
   - å°‡åœ˜éšŠæˆå“¡åŠ å…¥ç¾¤çµ„
   - å°‡ `.env` ä¸­çš„ `EMAIL_ACCOUNT` è¨­ç‚ºç¾¤çµ„éƒµä»¶åœ°å€

2. **è‡ªå»ºéƒµä»¶åˆ—è¡¨**:
   ```bash
   # .env
   EMAIL_ACCOUNT=team-digest@your-company.com
   ```
   è®“ IT éƒ¨é–€è¨­å®š `team-digest@your-company.com` è½‰ç™¼çµ¦æ‰€æœ‰åœ˜éšŠæˆå“¡

---

## ğŸ” æ“´å¤§è³‡æ–™æœé›†ç¯„åœ

### 1. å¢åŠ  RSS Feeds æ•¸é‡

```python
# src/agents/scout_agent.py

DEFAULT_FEEDS = [
    # å­¸è¡“ä¾†æº (10+)
    "https://arxiv.org/rss/cs.AI",
    "https://arxiv.org/rss/cs.LG",
    "https://arxiv.org/rss/cs.CL",
    "https://arxiv.org/rss/cs.CV",
    "https://proceedings.mlr.press/feed.xml",

    # å…¬å¸èˆ‡ç ”ç©¶æ©Ÿæ§‹ (20+)
    "https://openai.com/blog/rss",
    "https://www.anthropic.com/blog/rss",
    "https://www.deepmind.com/blog/rss.xml",
    "https://ai.meta.com/blog/rss/",
    "https://aws.amazon.com/blogs/machine-learning/feed/",
    "https://azure.microsoft.com/en-us/blog/topics/ai/feed/",

    # é–‹æºç¤¾ç¾¤ (10+)
    "https://huggingface.co/blog/feed.xml",
    "https://blog.langchain.dev/feed/",
    "https://www.llamaindex.ai/blog/rss.xml",

    # åª’é«”èˆ‡æ–°è (10+)
    "https://techcrunch.com/category/artificial-intelligence/feed/",
    "https://venturebeat.com/category/ai/feed/",
    "https://www.technologyreview.com/topic/artificial-intelligence/feed/",
]
```

**æ³¨æ„äº‹é …**:
- RSS feed è¶Šå¤šï¼ŒæŠ“å–æ™‚é–“è¶Šé•·
- å»ºè­°åˆ†æ‰¹æ¸¬è©¦ï¼Œç¢ºä¿æ¯å€‹ feed éƒ½æœ‰æ•ˆ
- å¯èƒ½éœ€è¦èª¿æ•´ timeout è¨­å®šï¼ˆè¦‹ä¸‹æ–¹ï¼‰

### 2. å¢åŠ æœç´¢æŸ¥è©¢æ•¸é‡èˆ‡é »ç‡

```python
# src/agents/scout_agent.py

# å¢åŠ æœç´¢æŸ¥è©¢
DEFAULT_SEARCH_QUERIES = [
    # åŸæœ‰æŸ¥è©¢ (5-10å€‹)
    # ...

    # æ–°å¢æŸ¥è©¢ (10-20å€‹)
    # æŒ‰ä¸»é¡Œåˆ†é¡
    "large language model benchmarks",
    "AI agent reasoning capabilities",
    "vision transformer architecture",
    # ...
]

# èª¿æ•´æœç´¢åƒæ•¸
def search_articles(queries: List[str], max_results_per_query: int = 5):
    """
    Args:
        max_results_per_query: æ¯å€‹æŸ¥è©¢çš„æœ€å¤§çµæœæ•¸ï¼ˆé è¨­ 5ï¼Œå¯èª¿æ•´è‡³ 10-20ï¼‰
    """
```

### 3. æ–°å¢å…¶ä»–è³‡æ–™ä¾†æº

#### æ–¹æ³• A: æ–°å¢ Twitter/X APIï¼ˆéœ€ç”³è«‹ API Keyï¼‰

```python
# src/tools/twitter_fetcher.py

import tweepy
from typing import List, Dict

def fetch_tweets(
    keywords: List[str],
    max_tweets: int = 50
) -> List[Dict]:
    """
    å¾ Twitter æŠ“å–ç›¸é—œæ¨æ–‡

    éœ€è¦è¨­å®š .env:
        TWITTER_API_KEY=xxx
        TWITTER_API_SECRET=xxx
        TWITTER_ACCESS_TOKEN=xxx
        TWITTER_ACCESS_TOKEN_SECRET=xxx
    """
    # å¯¦ä½œç•¥
    pass
```

#### æ–¹æ³• B: æ–°å¢ Reddit API

```python
# src/tools/reddit_fetcher.py

import praw
from typing import List, Dict

def fetch_reddit_posts(
    subreddits: List[str] = ["MachineLearning", "artificial", "LocalLLaMA"],
    time_filter: str = "day",  # day, week, month
    limit: int = 50
) -> List[Dict]:
    """
    å¾ Reddit æŠ“å–ç†±é–€è²¼æ–‡

    éœ€è¦è¨­å®š .env:
        REDDIT_CLIENT_ID=xxx
        REDDIT_CLIENT_SECRET=xxx
        REDDIT_USER_AGENT=InsightCosmos/1.0
    """
    # å¯¦ä½œç•¥
    pass
```

#### æ–¹æ³• C: æ–°å¢ GitHub Trending

```python
# src/tools/github_fetcher.py

import requests
from typing import List, Dict

def fetch_trending_repos(
    language: str = "python",
    since: str = "daily"  # daily, weekly, monthly
) -> List[Dict]:
    """
    å¾ GitHub Trending æŠ“å–ç†±é–€å°ˆæ¡ˆ

    ä½¿ç”¨ GitHub Trending API (éå®˜æ–¹):
    https://github-trending-api.now.sh/repositories?language=python&since=daily
    """
    url = f"https://github-trending-api.now.sh/repositories"
    params = {"language": language, "since": since}
    response = requests.get(url, params=params)
    return response.json()
```

ç„¶å¾Œåœ¨ `src/agents/scout_agent.py` ä¸­æ•´åˆï¼š

```python
# src/agents/scout_agent.py

from src.tools.twitter_fetcher import fetch_tweets
from src.tools.reddit_fetcher import fetch_reddit_posts
from src.tools.github_fetcher import fetch_trending_repos

def collect_articles(
    user_prompt: str = None,
    enable_twitter: bool = False,
    enable_reddit: bool = True,
    enable_github: bool = True
) -> Dict[str, Any]:
    articles = []

    # åŸæœ‰ä¾†æº
    articles.extend(fetch_rss_articles(...))
    articles.extend(search_articles(...))

    # æ–°å¢ä¾†æºï¼ˆå¯é¸ï¼‰
    if enable_twitter:
        articles.extend(fetch_tweets(...))

    if enable_reddit:
        articles.extend(fetch_reddit_posts(...))

    if enable_github:
        articles.extend(fetch_trending_repos(...))

    # å»é‡èˆ‡è¿”å›
    return deduplicate_and_return(articles)
```

---

## ğŸ¤– æ›´æ› LLM æ¨¡å‹

InsightCosmos ä½¿ç”¨ **Google ADK (Agent Development Kit)**ï¼Œæ”¯æ´å¤šç¨® LLM æ¨¡å‹ã€‚

### 1. ä½¿ç”¨ä¸åŒçš„ Gemini æ¨¡å‹

ç·¨è¼¯ `src/agents/analyst_agent.py` å’Œ `src/agents/curator_daily.py`ï¼š

```python
# src/agents/analyst_agent.py

from google.adk.genai import Gemini

def create_analyst_agent(...):
    agent = LlmAgent(
        name="AnalystAgent",
        # é¸é … 1: Gemini 2.5 Flash (é è¨­ï¼Œå¿«é€Ÿï¼Œä¾¿å®œ)
        model=Gemini(model="gemini-2.5-flash"),

        # é¸é … 2: Gemini 2.0 Flash (ç©©å®šç‰ˆ)
        # model=Gemini(model="gemini-2.0-flash-exp"),

        # é¸é … 3: Gemini 2.5 Pro (æ›´å¼·å¤§ï¼Œä½†æ›´è²´æ›´æ…¢)
        # model=Gemini(model="gemini-2.5-pro-preview"),

        # é¸é … 4: Gemini 1.5 Pro (ç©©å®šç‰ˆ)
        # model=Gemini(model="gemini-1.5-pro"),

        instruction=ANALYST_INSTRUCTION,
        tools=[],
        output_key="analysis"
    )
    return agent
```

### 2. ä½¿ç”¨ OpenAI GPT æ¨¡å‹ï¼ˆéœ€é¡å¤–é…ç½®ï¼‰

ADK ä¹Ÿæ”¯æ´ OpenAI æ¨¡å‹ã€‚éœ€å…ˆå®‰è£ä¸¦é…ç½®ï¼š

```bash
# .env
OPENAI_API_KEY=sk-xxx
```

```python
# src/agents/analyst_agent.py

from google.adk.openai import OpenAI  # æ³¨æ„ï¼šå¾ ADK å°å…¥

def create_analyst_agent(...):
    agent = LlmAgent(
        name="AnalystAgent",
        # ä½¿ç”¨ OpenAI GPT-4o
        model=OpenAI(model="gpt-4o"),

        # æˆ– GPT-4o-mini (æ›´ä¾¿å®œ)
        # model=OpenAI(model="gpt-4o-mini"),

        instruction=ANALYST_INSTRUCTION,
        tools=[],
        output_key="analysis"
    )
    return agent
```

### 3. ä½¿ç”¨ Anthropic Claude æ¨¡å‹

```bash
# .env
ANTHROPIC_API_KEY=sk-ant-xxx
```

```python
# src/agents/analyst_agent.py

from google.adk.anthropic import Anthropic

def create_analyst_agent(...):
    agent = LlmAgent(
        name="AnalystAgent",
        # ä½¿ç”¨ Claude 3.7 Sonnet
        model=Anthropic(model="claude-3-7-sonnet-20250219"),

        # æˆ– Claude 3.5 Haiku (æœ€ä¾¿å®œ)
        # model=Anthropic(model="claude-3-5-haiku"),

        instruction=ANALYST_INSTRUCTION,
        tools=[],
        output_key="analysis"
    )
    return agent
```

### æ¨¡å‹é¸æ“‡å»ºè­°

| å ´æ™¯ | æ¨è–¦æ¨¡å‹ | åŸå›  |
|-----|---------|------|
| æˆæœ¬å„ªå…ˆ | Gemini 2.5 Flash | æœ€ä¾¿å®œï¼Œé€Ÿåº¦å¿« |
| é€Ÿåº¦å„ªå…ˆ | Gemini 2.0 Flash | è¶…å¿«éŸ¿æ‡‰ï¼Œé©åˆå³æ™‚ |
| å“è³ªå„ªå…ˆ | Claude 3.7 Sonnet | æ¨ç†èƒ½åŠ›å¼·ï¼Œæ–‡å­—å“è³ªé«˜ |
| å¹³è¡¡é¸æ“‡ | GPT-4o | é€Ÿåº¦èˆ‡å“è³ªå…¼é¡§ |
| æ¸¬è©¦é–‹ç™¼ | Gemini Flash | å…è²»é¡åº¦é«˜ï¼Œé©åˆé–‹ç™¼ |

---

## ğŸ“Š è³‡æ–™ç®¡ç†

### 1. æŸ¥çœ‹è³‡æ–™åº«å…§å®¹

#### æ–¹æ³• A: ä½¿ç”¨ SQLite å‘½ä»¤åˆ—å·¥å…·

```bash
# é€²å…¥è³‡æ–™åº«
sqlite3 data/insights.db

# æŸ¥çœ‹æ‰€æœ‰æ–‡ç« 
SELECT id, title, source, status, priority_score, created_at FROM articles ORDER BY created_at DESC LIMIT 10;

# æŸ¥çœ‹é«˜å„ªå…ˆåº¦æ–‡ç« 
SELECT id, title, priority_score FROM articles WHERE priority_score >= 0.8 ORDER BY priority_score DESC;

# æŸ¥çœ‹å„ä¾†æºçš„æ–‡ç« æ•¸é‡
SELECT source_name, COUNT(*) as count FROM articles GROUP BY source_name ORDER BY count DESC;

# æŸ¥çœ‹å„ç‹€æ…‹çš„æ–‡ç« æ•¸é‡
SELECT status, COUNT(*) as count FROM articles GROUP BY status;

# åŒ¯å‡ºç‚º CSV
.headers on
.mode csv
.output articles_export.csv
SELECT * FROM articles WHERE created_at > date('now', '-7 days');
.output stdout
```

#### æ–¹æ³• B: ä½¿ç”¨ Python è…³æœ¬

å‰µå»ºæŸ¥è©¢å·¥å…·ï¼š

```python
# scripts/query_database.py

import sys
from pathlib import Path
sys.path.insert(0, str(Path(__file__).parent.parent))

from src.memory.database import Database
from src.utils.config import Config
import json

def main():
    config = Config.from_env()
    db = Database.from_config(config)

    # æŸ¥è©¢æœ€è¿‘ 7 å¤©çš„é«˜åˆ†æ–‡ç« 
    query = """
    SELECT id, title, source_name, priority_score, created_at
    FROM articles
    WHERE created_at > date('now', '-7 days')
      AND priority_score >= 0.7
    ORDER BY priority_score DESC, created_at DESC
    """

    results = db.conn.execute(query).fetchall()

    print(f"Found {len(results)} high-priority articles:")
    print("=" * 80)

    for row in results:
        print(f"[{row[4]}] ({row[3]:.2f}) {row[1]}")
        print(f"  Source: {row[2]}")
        print()

if __name__ == "__main__":
    main()
```

ä½¿ç”¨ï¼š

```bash
python scripts/query_database.py
```

#### æ–¹æ³• C: ä½¿ç”¨ SQLite GUI å·¥å…·

æ¨è–¦å·¥å…·ï¼š
- **DB Browser for SQLite** (å…è²»): https://sqlitebrowser.org/
- **TablePlus** (Mac/Windows): https://tableplus.com/
- **DataGrip** (JetBrains): https://www.jetbrains.com/datagrip/

æ­¥é©Ÿï¼š
1. ä¸‹è¼‰ä¸¦å®‰è£å·¥å…·
2. é–‹å•Ÿ `data/insights.db`
3. ä½¿ç”¨ GUI ç€è¦½ã€æŸ¥è©¢ã€åŒ¯å‡ºè³‡æ–™

### 2. æ¸…ç†èˆŠè³‡æ–™

```python
# scripts/cleanup_old_data.py

import sys
from pathlib import Path
sys.path.insert(0, str(Path(__file__).parent.parent))

from src.memory.database import Database
from src.utils.config import Config
from datetime import datetime, timedelta

def cleanup_old_articles(days: int = 90):
    """
    åˆªé™¤ N å¤©å‰çš„æ–‡ç« 

    Args:
        days: ä¿ç•™æœ€è¿‘ N å¤©çš„è³‡æ–™ï¼ˆé è¨­ 90 å¤©ï¼‰
    """
    config = Config.from_env()
    db = Database.from_config(config)

    cutoff_date = datetime.now() - timedelta(days=days)

    # è¨ˆç®—è¦åˆªé™¤çš„æ•¸é‡
    count_query = "SELECT COUNT(*) FROM articles WHERE created_at < ?"
    count = db.conn.execute(count_query, (cutoff_date,)).fetchone()[0]

    print(f"Found {count} articles older than {days} days")

    if count == 0:
        print("No articles to delete")
        return

    # ç¢ºèª
    confirm = input(f"Delete {count} articles? (yes/no): ")
    if confirm.lower() != 'yes':
        print("Cancelled")
        return

    # åˆªé™¤æ–‡ç« 
    delete_query = "DELETE FROM articles WHERE created_at < ?"
    db.conn.execute(delete_query, (cutoff_date,))
    db.conn.commit()

    print(f"Deleted {count} articles")

    # VACUUM é‡‹æ”¾ç©ºé–“
    print("Optimizing database...")
    db.conn.execute("VACUUM")
    print("Done!")

if __name__ == "__main__":
    import argparse
    parser = argparse.ArgumentParser(description="Clean up old articles")
    parser.add_argument("--days", type=int, default=90, help="Keep articles from last N days")
    args = parser.parse_args()

    cleanup_old_articles(args.days)
```

ä½¿ç”¨ï¼š

```bash
# åˆªé™¤ 90 å¤©å‰çš„è³‡æ–™
python scripts/cleanup_old_data.py

# åˆªé™¤ 30 å¤©å‰çš„è³‡æ–™
python scripts/cleanup_old_data.py --days 30
```

### 3. åŒ¯å‡ºè³‡æ–™

```python
# scripts/export_data.py

import sys
from pathlib import Path
sys.path.insert(0, str(Path(__file__).parent.parent))

from src.memory.database import Database
from src.utils.config import Config
import json
import csv
from datetime import datetime

def export_to_json(output_file: str = "export.json"):
    """åŒ¯å‡ºè³‡æ–™ç‚º JSON"""
    config = Config.from_env()
    db = Database.from_config(config)

    query = "SELECT * FROM articles ORDER BY created_at DESC"
    results = db.conn.execute(query).fetchall()

    # å–å¾—æ¬„ä½åç¨±
    columns = [description[0] for description in db.conn.execute(query).description]

    # è½‰æ›ç‚º dict list
    data = [dict(zip(columns, row)) for row in results]

    # å¯«å…¥ JSON
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2, default=str)

    print(f"Exported {len(data)} articles to {output_file}")

def export_to_csv(output_file: str = "export.csv"):
    """åŒ¯å‡ºè³‡æ–™ç‚º CSV"""
    config = Config.from_env()
    db = Database.from_config(config)

    query = "SELECT * FROM articles ORDER BY created_at DESC"
    results = db.conn.execute(query).fetchall()

    # å–å¾—æ¬„ä½åç¨±
    columns = [description[0] for description in db.conn.execute(query).description]

    # å¯«å…¥ CSV
    with open(output_file, 'w', encoding='utf-8', newline='') as f:
        writer = csv.writer(f)
        writer.writerow(columns)
        writer.writerows(results)

    print(f"Exported {len(results)} articles to {output_file}")

if __name__ == "__main__":
    import argparse
    parser = argparse.ArgumentParser(description="Export database")
    parser.add_argument("--format", choices=["json", "csv"], default="json", help="Export format")
    parser.add_argument("--output", help="Output file name")
    args = parser.parse_args()

    if args.format == "json":
        output = args.output or f"export_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        export_to_json(output)
    else:
        output = args.output or f"export_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"
        export_to_csv(output)
```

ä½¿ç”¨ï¼š

```bash
# åŒ¯å‡ºç‚º JSON
python scripts/export_data.py --format json

# åŒ¯å‡ºç‚º CSV
python scripts/export_data.py --format csv --output my_data.csv
```

---

## ğŸš€ éƒ¨ç½²æŒ‡å—

### 1. æœ¬åœ°éƒ¨ç½²ï¼ˆè‡ªå‹•åŒ–ï¼‰

#### æ–¹æ³• A: Cron Jobï¼ˆLinux/Macï¼‰

```bash
# ç·¨è¼¯ crontab
crontab -e

# æ·»åŠ å®šæ™‚ä»»å‹™ï¼ˆæ¯å¤©æ—©ä¸Š 8 é»åŸ·è¡Œï¼‰
0 8 * * * cd /path/to/InsightCosmos && /path/to/venv/bin/python -m src.orchestrator.daily_runner >> /path/to/logs/daily.log 2>&1

# ä¿å­˜ä¸¦é€€å‡º
```

#### æ–¹æ³• B: systemd Serviceï¼ˆLinuxï¼‰

å‰µå»º systemd service æ–‡ä»¶ï¼š

```ini
# /etc/systemd/system/insightcosmos.service

[Unit]
Description=InsightCosmos Daily Pipeline
After=network.target

[Service]
Type=oneshot
User=youruser
WorkingDirectory=/path/to/InsightCosmos
ExecStart=/path/to/venv/bin/python -m src.orchestrator.daily_runner
StandardOutput=append:/path/to/logs/daily.log
StandardError=append:/path/to/logs/error.log

[Install]
WantedBy=multi-user.target
```

å‰µå»º timer æ–‡ä»¶ï¼š

```ini
# /etc/systemd/system/insightcosmos.timer

[Unit]
Description=Run InsightCosmos Daily at 8 AM

[Timer]
OnCalendar=daily
OnCalendar=08:00
Persistent=true

[Install]
WantedBy=timers.target
```

å•Ÿç”¨ service:

```bash
# é‡æ–°è¼‰å…¥ systemd
sudo systemctl daemon-reload

# å•Ÿç”¨ timer
sudo systemctl enable insightcosmos.timer

# å•Ÿå‹• timer
sudo systemctl start insightcosmos.timer

# æŸ¥çœ‹ç‹€æ…‹
sudo systemctl status insightcosmos.timer
```

### 2. éƒ¨ç½²åˆ° Google Cloud Run

**å„ªé»**:
- å®Œå…¨è¨—ç®¡
- è‡ªå‹•æ“´å±•ï¼ˆåŒ…æ‹¬ç¸®æ¸›è‡³ 0ï¼‰
- èˆ‡ Google AI æ•´åˆè‰¯å¥½

**æ­¥é©Ÿ**:

1. å‰µå»º `Dockerfile`:
```dockerfile
FROM python:3.11-slim

WORKDIR /app

# å®‰è£ä¾è³´
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# è¤‡è£½ç¨‹å¼ç¢¼
COPY . .

# åˆå§‹åŒ–è³‡æ–™åº«
RUN python -m src.memory.database

# é‹è¡Œ
CMD ["python", "-m", "src.orchestrator.daily_runner"]
```

2. éƒ¨ç½²åˆ° Cloud Run:
```bash
# å®‰è£ gcloud CLI
# https://cloud.google.com/sdk/docs/install

# ç™»å…¥
gcloud auth login

# è¨­å®šå°ˆæ¡ˆ
gcloud config set project YOUR_PROJECT_ID

# æ§‹å»ºä¸¦éƒ¨ç½²
gcloud run deploy insightcosmos \
  --source . \
  --region us-central1 \
  --platform managed \
  --allow-unauthenticated \
  --set-env-vars GOOGLE_API_KEY=xxx,EMAIL_ACCOUNT=xxx,EMAIL_PASSWORD=xxx
```

3. è¨­å®š Cloud Schedulerï¼ˆå®šæ™‚åŸ·è¡Œï¼‰:
```bash
gcloud scheduler jobs create http daily-pipeline \
  --schedule="0 8 * * *" \
  --uri="https://insightcosmos-xxx.run.app" \
  --http-method=GET
```

---

## ğŸ’¾ å‚™ä»½èˆ‡é‚„åŸ

### 1. è³‡æ–™åº«å‚™ä»½

#### è‡ªå‹•å‚™ä»½è…³æœ¬

```python
# scripts/backup_database.py

import sys
from pathlib import Path
sys.path.insert(0, str(Path(__file__).parent.parent))

import shutil
from datetime import datetime
from src.utils.config import Config

def backup_database(backup_dir: str = "backups"):
    """
    å‚™ä»½è³‡æ–™åº«

    Args:
        backup_dir: å‚™ä»½ç›®éŒ„
    """
    config = Config.from_env()
    db_path = Path(config.database_path)

    if not db_path.exists():
        print(f"Database not found: {db_path}")
        return

    # å‰µå»ºå‚™ä»½ç›®éŒ„
    backup_path = Path(backup_dir)
    backup_path.mkdir(exist_ok=True)

    # å‚™ä»½æª”æ¡ˆåç¨±ï¼ˆåŒ…å«æ™‚é–“æˆ³ï¼‰
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    backup_file = backup_path / f"insights_backup_{timestamp}.db"

    # è¤‡è£½è³‡æ–™åº«
    print(f"Backing up database to {backup_file}...")
    shutil.copy2(db_path, backup_file)

    # å£“ç¸®å‚™ä»½ï¼ˆå¯é¸ï¼‰
    import gzip
    with open(backup_file, 'rb') as f_in:
        with gzip.open(f"{backup_file}.gz", 'wb') as f_out:
            shutil.copyfileobj(f_in, f_out)

    # åˆªé™¤æœªå£“ç¸®çš„å‚™ä»½
    backup_file.unlink()

    print(f"Backup completed: {backup_file}.gz")

if __name__ == "__main__":
    import argparse
    parser = argparse.ArgumentParser(description="Backup InsightCosmos database")
    parser.add_argument("--dir", default="backups", help="Backup directory")
    args = parser.parse_args()

    backup_database(args.dir)
```

ä½¿ç”¨ï¼š

```bash
# æ‰‹å‹•å‚™ä»½
python scripts/backup_database.py

# æŒ‡å®šå‚™ä»½ç›®éŒ„
python scripts/backup_database.py --dir /path/to/backups
```

### 2. é‚„åŸè³‡æ–™åº«

```bash
# è§£å£“ç¸®å‚™ä»½
gunzip backups/insights_backup_20251126_080000.db.gz

# è¦†è“‹ç¾æœ‰è³‡æ–™åº«
cp backups/insights_backup_20251126_080000.db data/insights.db
```

---

## â“ å¸¸è¦‹å•é¡Œ

### Q1: å¦‚ä½•æ¸¬è©¦éƒµä»¶é…ç½®æ˜¯å¦æ­£ç¢ºï¼Ÿ

```bash
# ä½¿ç”¨æ¸¬è©¦è…³æœ¬
python -c "
from src.tools.email_sender import EmailSender, EmailConfig
from src.utils.config import Config

config = Config.from_env()
email_config = EmailConfig(
    sender_email=config.email_account,
    sender_password=config.email_password
)

sender = EmailSender(email_config)
result = sender.send(
    to_email=config.email_account,
    subject='InsightCosmos Test Email',
    text_body='This is a test email from InsightCosmos.'
)
print(result)
"
```

### Q2: å¦‚ä½•æŸ¥çœ‹ Pipeline åŸ·è¡Œæ—¥èªŒï¼Ÿ

```bash
# æŸ¥çœ‹æœ€è¿‘çš„æ—¥èªŒ
tail -f logs/insightcosmos.log

# æœå°‹ç‰¹å®šéŒ¯èª¤
grep "ERROR" logs/insightcosmos.log

# æŸ¥çœ‹ç‰¹å®šæ—¥æœŸçš„æ—¥èªŒ
cat logs/insightcosmos.log | grep "2025-11-26"
```

### Q3: å¦‚ä½•é™åˆ¶ API ä½¿ç”¨æˆæœ¬ï¼Ÿ

1. æ¸›å°‘æ¯æ—¥è™•ç†æ–‡ç« æ•¸é‡
2. ä½¿ç”¨æ›´ä¾¿å®œçš„æ¨¡å‹ï¼ˆGemini Flashï¼‰
3. æ¸›å°‘ RSS feeds å’Œæœç´¢æŸ¥è©¢æ•¸é‡

### Q4: å¦‚ä½•åŠ å¿« Pipeline åŸ·è¡Œé€Ÿåº¦ï¼Ÿ

1. ä½¿ç”¨æ›´å¿«çš„ LLM æ¨¡å‹ï¼ˆGemini 2.5 Flashï¼‰
2. æ¸›å°‘è³‡æ–™ä¾†æºæ•¸é‡
3. èª¿æ•´ `max_articles` åƒæ•¸

### Q5: å¦‚ä½•è™•ç† Rate Limit éŒ¯èª¤ï¼Ÿ

åœ¨ orchestrator ä¸­æ·»åŠ å»¶é²ï¼š

```python
# src/orchestrator/daily_runner.py

import time

for idx, article_dict in enumerate(pending_articles, 1):
    # æ¯åˆ†æ 5 ç¯‡æ–‡ç« ï¼Œæš«åœ 10 ç§’
    if idx % 5 == 0:
        self.logger.info("  Pausing to avoid rate limit...")
        time.sleep(10)

    # åˆ†ææ–‡ç« 
    result = runner.analyze_article(...)
```

---

## ğŸ”§ æ•…éšœæ’é™¤

### å•é¡Œ 1: ç„¡æ³•ç™¼é€éƒµä»¶ï¼ˆAuthentication Failedï¼‰

**ç—‡ç‹€**:
```
SMTPAuthenticationError: (535, b'5.7.8 Username and Password not accepted')
```

**è§£æ±ºæ–¹æ¡ˆ**:

1. ç¢ºèªä½¿ç”¨çš„æ˜¯ **App Password**ï¼ˆä¸æ˜¯å¸³è™Ÿå¯†ç¢¼ï¼‰
   - Gmail: https://support.google.com/accounts/answer/185833
   - å‰å¾€ Google å¸³æˆ¶ â†’ å®‰å…¨æ€§ â†’ å…©æ­¥é©Ÿé©—è­‰ â†’ æ‡‰ç”¨ç¨‹å¼å¯†ç¢¼
   - ç”Ÿæˆæ–°çš„æ‡‰ç”¨ç¨‹å¼å¯†ç¢¼
   - å°‡å¯†ç¢¼æ›´æ–°åˆ° `.env` çš„ `EMAIL_PASSWORD`

2. ç¢ºèª `.env` æ ¼å¼æ­£ç¢ºï¼ˆç„¡å¤šé¤˜ç©ºæ ¼ï¼‰:
   ```bash
   EMAIL_ACCOUNT=your_email@gmail.com
   EMAIL_PASSWORD=abcd efgh ijkl mnop  # æ³¨æ„ï¼šApp Password åŒ…å«ç©ºæ ¼æ˜¯æ­£å¸¸çš„
   ```

### å•é¡Œ 2: Google Search Grounding å¤±æ•—

**ç—‡ç‹€**:
```
Error: Google Search Grounding failed
```

**è§£æ±ºæ–¹æ¡ˆ**:

1. ç¢ºèª API Key æœ‰æ•ˆä¸”æœ‰ Search Grounding æ¬Šé™
   - è¨ªå• [Google AI Studio](https://aistudio.google.com/apikey)
   - ç¢ºèª API Key ç‹€æ…‹ç‚º "Active"
   - ç¢ºèªæœ‰è¶³å¤ çš„å…è²»é…é¡

2. æª¢æŸ¥ç¶²è·¯é€£ç·šï¼ˆSearch Grounding éœ€è¦ç¶²è·¯ï¼‰

### å•é¡Œ 3: è³‡æ–™åº«é–å®šï¼ˆDatabase is lockedï¼‰

**ç—‡ç‹€**:
```
sqlite3.OperationalError: database is locked
```

**åŸå› **: å¤šå€‹ç¨‹åºåŒæ™‚å­˜å– SQLite è³‡æ–™åº«

**è§£æ±ºæ–¹æ¡ˆ**:

1. ç¢ºèªæ²’æœ‰å¤šå€‹ Pipeline åŒæ™‚é‹è¡Œ:
   ```bash
   ps aux | grep daily_runner
   # å¦‚æœæœ‰å¤šå€‹ï¼Œåˆªé™¤å¤šé¤˜çš„
   kill <PID>
   ```

2. å¢åŠ  SQLite timeout:
   ```python
   # src/memory/database.py

   self.conn = sqlite3.connect(
       database_path,
       timeout=30.0  # å¢åŠ  timeoutï¼ˆé è¨­ 5.0ï¼‰
   )
   ```

### å•é¡Œ 4: RSS Feed ç„¡æ³•è®€å–

**ç—‡ç‹€**:
```
Error fetching RSS feed: HTTP 403 Forbidden
```

**åŸå› **: æŸäº›ç¶²ç«™å°é–çˆ¬èŸ²æˆ– feedparser çš„é è¨­ User-Agent

**è§£æ±ºæ–¹æ¡ˆ**:

ä¿®æ”¹ `src/tools/fetcher.py` æ·»åŠ  User-Agent:

```python
# src/tools/fetcher.py

import feedparser
import requests

def fetch_rss_feed(feed_url: str) -> Dict[str, Any]:
    try:
        # ä½¿ç”¨ requests å…ˆå–å¾—å…§å®¹ï¼ˆå¸¶è‡ªè¨‚ User-Agentï¼‰
        headers = {
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36'
        }
        response = requests.get(feed_url, headers=headers, timeout=10)
        response.raise_for_status()

        # å†ç”¨ feedparser è§£æ
        feed = feedparser.parse(response.content)

        # ... ç¹¼çºŒè™•ç†
    except Exception as e:
        # ...
```

---

## ğŸ“ˆ æ•ˆèƒ½æŒ‡æ¨™

Phase 1 å®Œæ•´ç‰ˆçš„æ•ˆèƒ½æŒ‡æ¨™ï¼š

| æŒ‡æ¨™ | ç›®æ¨™ | å¯¦éš› | ç‹€æ…‹ |
|------|------|------|------|
| Daily Pipeline åŸ·è¡Œæ™‚é–“ | < 5 åˆ†é˜ | 2-3 åˆ†é˜ | âœ… |
| Weekly Pipeline åŸ·è¡Œæ™‚é–“ | < 2 åˆ†é˜ | ~17 ç§’ | âœ… |
| å–®æ–‡ç« åˆ†ææ™‚é–“ | < 15 ç§’ | 3-5 ç§’ | âœ… |
| RSS æ‰¹é‡æŠ“å– (10 feeds) | < 30 ç§’ | 10-15 ç§’ | âœ… |
| æ¸¬è©¦è¦†è“‹ç‡ | >= 95% | 97.4% | âœ… |

---

## ğŸ“ æ”¯æ´èˆ‡ç¤¾ç¾¤

### ç²å–å¹«åŠ©

- **GitHub Issues**: https://github.com/your-repo/InsightCosmos/issues
- **æ–‡ä»¶ç›®éŒ„**: `docs/` è³‡æ–™å¤¾åŒ…å«å®Œæ•´æŠ€è¡“æ–‡ä»¶
- **API åƒè€ƒ**: `docs/implementation/api_reference.md`

### ç›¸é—œæ–‡ä»¶

- [README.md](README.md) - Project description and quick start (English)
- [README_zh_TW.md](README_zh_TW.md) - å°ˆæ¡ˆèªªæ˜èˆ‡å¿«é€Ÿé–‹å§‹ï¼ˆç¹é«”ä¸­æ–‡ï¼‰
- [USER_MANUAL.md](USER_MANUAL.md) - Complete User Manual (English)
- [CLAUDE.md](CLAUDE.md) - Claude Code å°ˆæ¡ˆæŒ‡å—
- [PROGRESS.md](PROGRESS.md) - é–‹ç™¼é€²åº¦è¿½è¹¤
- `docs/planning/` - è¦åŠƒæ–‡ä»¶
- `docs/implementation/` - å¯¦ä½œæ–‡ä»¶
- `docs/validation/` - æ¸¬è©¦èˆ‡é©—è­‰å ±å‘Š
- `docs/optimization/` - æ•ˆèƒ½å„ªåŒ–ç´€éŒ„

### æˆæ¬Š

MIT License - è©³è¦‹ `LICENSE` æª”æ¡ˆ

---

**æœ€å¾Œæ›´æ–°**: 2025-11-26
**ç¶­è­·è€…**: Ray å¼µç‘æ¶µ
**ç‰ˆæœ¬**: 1.1.0 (Phase 1 å®Œæ•´ç‰ˆ)
