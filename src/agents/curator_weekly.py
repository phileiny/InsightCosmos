"""
Curator Weekly Agent

æ¯é€±æ·±åº¦æƒ…å ±å ±å‘Šç”Ÿæˆå™¨ï¼Œè² è²¬ï¼š
1. èšåˆæœ¬é€±å·²åˆ†æçš„æ–‡ç« 
2. é€²è¡Œå‘é‡èšé¡è­˜åˆ¥ä¸»é¡Œ
3. åˆ†æç†±é–€è¶¨å‹¢èˆ‡æ–°èˆˆè©±é¡Œ
4. ä½¿ç”¨ LLM ç”Ÿæˆæ·±åº¦å ±å‘Š
5. æ ¼å¼åŒ–ä¸¦ç™¼é€ Email

Author: Ray å¼µç‘æ¶µ
Created: 2025-11-25
Version: 1.0.0
"""

from typing import List, Dict, Any, Optional
from datetime import datetime, timedelta
import json
import numpy as np

from google.adk.agents import LlmAgent
from google.adk.sessions import InMemorySessionService
from google.adk.runners import Runner
from google.genai import types as genai_types

from src.utils.config import Config
from src.utils.logger import setup_logger
from src.memory.database import Database
from src.memory.article_store import ArticleStore
from src.memory.embedding_store import EmbeddingStore
from src.tools.vector_clustering import VectorClusteringTool
from src.tools.trend_analysis import TrendAnalysisTool
from src.tools.digest_formatter import DigestFormatter
from src.tools.email_sender import EmailSender


def create_weekly_curator_agent() -> LlmAgent:
    """
    å‰µå»º Weekly Curator Agent

    Returns:
        LlmAgent: Weekly Curator Agent å¯¦ä¾‹

    Example:
        >>> agent = create_weekly_curator_agent()
        >>> print(agent.name)
        WeeklyCurator
    """
    # è¼‰å…¥ Prompt
    with open("prompts/weekly_prompt.txt", "r", encoding="utf-8") as f:
        prompt = f.read()

    # å‰µå»º Agentï¼ˆä¸éœ€è¦é¡å¤–å·¥å…·ï¼Œæ•¸æ“šå·²é è™•ç†ï¼‰
    # æ ¹æ“š ADK æ–‡ä»¶ï¼ŒPython ä¸­ç›´æ¥ä½¿ç”¨æ¨¡å‹å­—ä¸²
    agent = LlmAgent(
        name="WeeklyCurator",
        model="gemini-2.0-flash",  # ä½¿ç”¨ç©©å®šç‰ˆæ¨¡å‹
        instruction=prompt,
        tools=[],  # Weekly Curator ä¸éœ€è¦å·¥å…·ï¼Œç›´æ¥æ¥æ”¶è™•ç†å¥½çš„æ•¸æ“š
        output_key="weekly_report"
    )

    return agent


class CuratorWeeklyRunner:
    """
    Weekly Curator Agent é‹è¡Œå™¨

    è² è²¬å®Œæ•´çš„é€±å ±ç”Ÿæˆæµç¨‹ï¼š
    1. æŸ¥è©¢æœ¬é€±æ–‡ç« èˆ‡ Embeddings
    2. å‘é‡èšé¡
    3. è¶¨å‹¢åˆ†æ
    4. LLM ç”Ÿæˆå ±å‘Š
    5. æ ¼å¼åŒ– HTML/Text
    6. ç™¼é€ Email

    Attributes:
        config (Config): é…ç½®å°è±¡
        db (Database): è³‡æ–™åº«é€£æ¥
        article_store (ArticleStore): æ–‡ç« å­˜å„²
        embedding_store (EmbeddingStore): å‘é‡å­˜å„²
        logger (Logger): æ—¥èªŒè¨˜éŒ„å™¨
    """

    def __init__(self, config: Config):
        """
        åˆå§‹åŒ– Weekly Curator Runner

        Args:
            config: é…ç½®å°è±¡
        """
        self.config = config
        self.db = Database.from_config(config)
        self.article_store = ArticleStore(self.db)
        self.embedding_store = EmbeddingStore(self.db)
        self.logger = setup_logger("WeeklyCurator")

    def generate_weekly_report(
        self,
        week_start: Optional[str] = None,  # "YYYY-MM-DD"
        week_end: Optional[str] = None,    # "YYYY-MM-DD"
        dry_run: bool = False
    ) -> Dict[str, Any]:
        """
        ç”Ÿæˆé€±å ±ä¸¦ç™¼é€

        Args:
            week_start: é€±é–‹å§‹æ—¥æœŸï¼ˆé»˜èªç‚º 7 å¤©å‰ï¼‰
            week_end: é€±çµæŸæ—¥æœŸï¼ˆé»˜èªç‚ºä»Šå¤©ï¼‰
            dry_run: æ˜¯å¦ç‚ºæ¸¬è©¦æ¨¡å¼ï¼ˆä¸ç™¼é€éƒµä»¶ï¼‰

        Returns:
            dict: {
                "status": "success" | "error",
                "subject": str,
                "recipients": list,
                "html_body": str,
                "text_body": str,
                "total_articles": int,
                "analyzed_articles": int,
                "num_clusters": int,
                "hot_trends": int,
                "emerging_topics": int,
                "email_sent": bool,
                "error_message": str,  # éŒ¯èª¤æ™‚
                "suggestion": str      # éŒ¯èª¤æ™‚
            }

        Example:
            >>> runner = CuratorWeeklyRunner(config)
            >>> result = runner.generate_weekly_report(dry_run=True)
            >>> print(result["subject"])
            InsightCosmos Weekly Report - 2025-11-18 to 2025-11-24
        """
        self.logger.info("=" * 60)
        self.logger.info("Weekly Report Generation Started")
        self.logger.info(f"Mode: {'DRY RUN' if dry_run else 'PRODUCTION'}")
        self.logger.info("=" * 60)

        # çµ±è¨ˆæ•¸æ“šæ”¶é›†
        stats = {
            "total_articles": 0,
            "analyzed_articles": 0,
            "num_clusters": 0,
            "hot_trends": 0,
            "emerging_topics": 0
        }

        try:
            # 1. æŸ¥è©¢æœ¬é€±æ–‡ç« 
            self.logger.info("\n[Step 1/5] Querying weekly articles...")
            articles = self._get_weekly_articles(week_start, week_end)

            if not articles:
                return {
                    "status": "error",
                    "error_type": "no_articles",
                    "error_message": "No analyzed articles found for this week",
                    "suggestion": "Run Daily Pipeline to collect and analyze articles first",
                    **stats
                }

            stats["total_articles"] = len(articles)
            stats["analyzed_articles"] = len(articles)
            self.logger.info(f"Found {len(articles)} analyzed articles")

            # 2. å‘é‡èšé¡
            self.logger.info("\n[Step 2/5] Clustering articles by topic...")
            clustering_result = self._cluster_articles(articles)

            if clustering_result["status"] != "success":
                return {**clustering_result, **stats}

            clusters = clustering_result["clusters"]
            stats["num_clusters"] = len(clusters)
            self.logger.info(f"Identified {len(clusters)} topic clusters")

            # 3. è¶¨å‹¢åˆ†æ
            self.logger.info("\n[Step 3/5] Analyzing trends...")
            trend_result = self._analyze_trends(articles, clusters)
            stats["hot_trends"] = len(trend_result['hot_trends'])
            stats["emerging_topics"] = len(trend_result['emerging_topics'])
            self.logger.info(f"Found {stats['hot_trends']} hot trends")
            self.logger.info(f"Found {stats['emerging_topics']} emerging topics")

            # 4. LLM ç”Ÿæˆå ±å‘Š
            self.logger.info("\n[Step 4/5] Generating report with LLM...")
            report_data = self._generate_report_with_llm(
                articles, clusters, trend_result, week_start, week_end
            )

            if report_data["status"] != "success":
                return {**report_data, **stats}

            # 5. æ ¼å¼åŒ–ä¸¦ç™¼é€
            self.logger.info("\n[Step 5/5] Formatting and sending email...")
            send_result = self._format_and_send(report_data["report"], dry_run)

            self.logger.info("\n" + "=" * 60)
            if send_result["status"] == "success":
                self.logger.info("Weekly Report Generation Completed Successfully")
            else:
                self.logger.error("Weekly Report Generation Failed")
            self.logger.info("=" * 60)

            # åˆä½µçµ±è¨ˆæ•¸æ“šåˆ°çµæœ
            send_result.update(stats)
            send_result["email_sent"] = not dry_run and send_result["status"] == "success"
            return send_result

        except Exception as e:
            self.logger.error(f"Weekly report generation failed: {e}", exc_info=True)
            return {
                "status": "error",
                "error_type": type(e).__name__,
                "error_message": str(e),
                "suggestion": "Check logs for detailed error information",
                **stats
            }

    def _get_weekly_articles(
        self,
        week_start: Optional[str],
        week_end: Optional[str]
    ) -> List[Dict[str, Any]]:
        """
        æŸ¥è©¢æœ¬é€±æ–‡ç« 

        Args:
            week_start: é€±é–‹å§‹æ—¥æœŸ
            week_end: é€±çµæŸæ—¥æœŸ

        Returns:
            List[dict]: æ–‡ç« åˆ—è¡¨
        """
        # è¨ˆç®—æ—¥æœŸç¯„åœï¼ˆé»˜èªç‚ºéå» 7 å¤©ï¼‰
        if week_end is None:
            end_date = datetime.now()
        else:
            end_date = datetime.strptime(week_end, "%Y-%m-%d")

        if week_start is None:
            start_date = end_date - timedelta(days=7)
        else:
            start_date = datetime.strptime(week_start, "%Y-%m-%d")

        self.logger.info(f"Date range: {start_date.date()} to {end_date.date()}")

        # æŸ¥è©¢å·²åˆ†æçš„æ–‡ç« ï¼ˆstatus='analyzed'ï¼‰
        articles = self.article_store.get_by_date_range(
            start_date=start_date.isoformat(),
            end_date=end_date.isoformat(),
            status="analyzed",
            min_priority=0.6  # éæ¿¾ä½å„ªå…ˆåº¦æ–‡ç« 
        )

        return articles

    def _cluster_articles(
        self,
        articles: List[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """
        å‘é‡èšé¡

        Args:
            articles: æ–‡ç« åˆ—è¡¨

        Returns:
            dict: èšé¡çµæœ
        """
        # ç²å–æ–‡ç«  IDs
        article_ids = [a["id"] for a in articles]

        # æŸ¥è©¢ Embeddings
        embeddings_data = self.embedding_store.get_embeddings(article_ids)

        if not embeddings_data:
            return {
                "status": "error",
                "error_type": "no_embeddings",
                "error_message": "No embeddings found for articles",
                "suggestion": "Ensure Analyst Agent has generated embeddings"
            }

        # å»ºç«‹ article_id -> embedding çš„æ˜ å°„
        embedding_map = {e["article_id"]: e["embedding"] for e in embeddings_data}

        # åªä¿ç•™æœ‰ embedding çš„æ–‡ç« 
        articles_with_embeddings = [
            article for article in articles
            if article["id"] in embedding_map
        ]

        # æª¢æŸ¥æ˜¯å¦æœ‰è¶³å¤ çš„æ–‡ç« é€²è¡Œèšé¡
        if len(articles_with_embeddings) < 2:
            return {
                "status": "error",
                "error_type": "insufficient_embeddings",
                "error_message": f"Only {len(articles_with_embeddings)} articles have embeddings (minimum: 2)",
                "suggestion": "Run Analyst Agent to generate more embeddings"
            }

        self.logger.info(
            f"Clustering {len(articles_with_embeddings)} articles "
            f"(filtered from {len(articles)} total)"
        )

        # çµ„ç¹”æˆ numpy çŸ©é™£ï¼ˆæŒ‰éæ¿¾å¾Œçš„æ–‡ç« é †åºï¼‰
        embeddings_matrix = np.array([
            embedding_map[article["id"]]
            for article in articles_with_embeddings
        ])

        # æº–å‚™å…ƒæ•¸æ“šï¼ˆä½¿ç”¨éæ¿¾å¾Œçš„æ–‡ç« ï¼‰
        metadata = []
        for article in articles_with_embeddings:
            metadata.append({
                "article_id": article["id"],
                "title": article["title"],
                "summary": article.get("summary", ""),
                "tags": article.get("tags", ""),
                "priority_score": article.get("priority_score", 0.0)
            })

        # å‹•æ…‹èª¿æ•´èšé¡æ•¸é‡ï¼ˆä½¿ç”¨æœ‰ embedding çš„æ–‡ç« æ•¸ï¼‰
        n_articles = len(articles_with_embeddings)
        if n_articles >= 40:
            n_clusters = 5
        elif n_articles >= 25:
            n_clusters = 4
        elif n_articles >= 15:
            n_clusters = 3
        else:
            n_clusters = 2

        self.logger.info(f"Using {n_clusters} clusters for {n_articles} articles")

        # åŸ·è¡Œèšé¡
        clustering_tool = VectorClusteringTool(n_clusters=n_clusters)
        result = clustering_tool.cluster_embeddings(embeddings_matrix, metadata)

        # å¦‚æœæˆåŠŸï¼Œæå–é—œéµå­—
        if result["status"] == "success":
            for cluster in result["clusters"]:
                keywords = clustering_tool.extract_cluster_keywords(
                    cluster, articles, top_k=5
                )
                cluster["keywords"] = keywords
                self.logger.info(
                    f"Cluster {cluster['cluster_id']}: "
                    f"{cluster['article_count']} articles, "
                    f"keywords: {', '.join(keywords[:3])}"
                )

        return result

    def _analyze_trends(
        self,
        articles: List[Dict[str, Any]],
        clusters: List[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """
        è¶¨å‹¢åˆ†æ

        Args:
            articles: æ–‡ç« åˆ—è¡¨
            clusters: èšé¡çµæœ

        Returns:
            dict: è¶¨å‹¢åˆ†æçµæœ
        """
        trend_tool = TrendAnalysisTool()

        # è­˜åˆ¥ç†±é–€è¶¨å‹¢
        hot_trends = trend_tool.identify_hot_trends(
            clusters,
            min_article_count=5,
            min_avg_priority=0.75
        )

        # åµæ¸¬æ–°èˆˆè©±é¡Œ
        emerging_topics = trend_tool.detect_emerging_topics(
            articles,
            previous_articles=None,  # Phase 1 ä¸æ¯”è¼ƒä¸Šé€±
            min_priority=0.7,
            min_article_count=2
        )

        return {
            "hot_trends": hot_trends,
            "emerging_topics": emerging_topics
        }

    def _generate_report_with_llm(
        self,
        articles: List[Dict[str, Any]],
        clusters: List[Dict[str, Any]],
        trend_result: Dict[str, Any],
        week_start: Optional[str],
        week_end: Optional[str]
    ) -> Dict[str, Any]:
        """
        ä½¿ç”¨ LLM ç”Ÿæˆå ±å‘Š

        Args:
            articles: æ–‡ç« åˆ—è¡¨
            clusters: èšé¡çµæœ
            trend_result: è¶¨å‹¢åˆ†æçµæœ
            week_start: é€±é–‹å§‹æ—¥æœŸ
            week_end: é€±çµæŸæ—¥æœŸ

        Returns:
            dict: LLM ç”Ÿæˆçš„å ±å‘Šæ•¸æ“š
        """
        # æº–å‚™è¼¸å…¥æ•¸æ“š
        input_data = self._prepare_llm_input(
            articles, clusters, trend_result, week_start, week_end
        )

        # å‰µå»º Agent
        agent = create_weekly_curator_agent()

        # èª¿ç”¨ Agentï¼ˆä½¿ç”¨ async æ–¹å¼ï¼Œåƒè€ƒ Daily Curatorï¼‰
        try:
            import asyncio
            from google.adk.runners import Runner
            from google.adk.sessions import InMemorySessionService
            from google.genai.types import Content, Part

            # å°‡è¼¸å…¥æ•¸æ“šè½‰ç‚º JSON å­—ä¸²
            input_json = json.dumps(input_data, ensure_ascii=False, indent=2)
            user_input = f"è«‹æ ¹æ“šä»¥ä¸‹æ•¸æ“šç”Ÿæˆé€±å ±ï¼š\n\n{input_json}"

            # å‰µå»º session service å’Œ runner
            session_service = InMemorySessionService()
            runner = Runner(
                agent=agent,
                app_name="InsightCosmos",
                session_service=session_service
            )

            # å®šç¾© async å‡½æ•¸
            async def invoke_llm_async():
                user_id = self.config.user_name or "user"
                session_id = "weekly_curator_session"

                # å‰µå»º session
                await session_service.create_session(
                    app_name="InsightCosmos",
                    user_id=user_id,
                    session_id=session_id
                )

                # åŸ·è¡Œ LLM
                response_text = ""
                events_gen = runner.run_async(
                    user_id=user_id,
                    session_id=session_id,
                    new_message=Content(parts=[Part(text=user_input)], role="user")
                )

                async for event in events_gen:
                    # æª¢æŸ¥æ˜¯å¦æ˜¯æœ€çµ‚éŸ¿æ‡‰
                    if event.is_final_response() and event.content and event.content.parts:
                        response_text = event.content.parts[0].text
                        break

                return response_text.strip() if response_text else None

            # åŸ·è¡Œ async å‡½æ•¸
            final_response = asyncio.run(invoke_llm_async())

            if not final_response:
                raise Exception("No final response from LLM")

            # è§£æè¼¸å‡º
            report_json = self._parse_llm_output(final_response)

            if report_json is None:
                return {
                    "status": "error",
                    "error_type": "parse_error",
                    "error_message": "Failed to parse LLM output as JSON",
                    "suggestion": "Check LLM output format in logs"
                }

            self.logger.info("LLM report generated successfully")

            return {
                "status": "success",
                "report": report_json
            }

        except Exception as e:
            self.logger.error(f"LLM generation failed: {e}", exc_info=True)
            return {
                "status": "error",
                "error_type": type(e).__name__,
                "error_message": str(e),
                "suggestion": "Check GOOGLE_API_KEY and API quota"
            }

    def _prepare_llm_input(
        self,
        articles: List[Dict[str, Any]],
        clusters: List[Dict[str, Any]],
        trend_result: Dict[str, Any],
        week_start: Optional[str],
        week_end: Optional[str]
    ) -> Dict[str, Any]:
        """
        æº–å‚™ LLM è¼¸å…¥æ•¸æ“š

        Args:
            articles: æ–‡ç« åˆ—è¡¨
            clusters: èšé¡çµæœ
            trend_result: è¶¨å‹¢åˆ†æçµæœ
            week_start: é€±é–‹å§‹æ—¥æœŸ
            week_end: é€±çµæŸæ—¥æœŸ

        Returns:
            dict: æ ¼å¼åŒ–çš„è¼¸å…¥æ•¸æ“š
        """
        # è¨ˆç®—æ—¥æœŸ
        if week_end is None:
            end_date = datetime.now().date()
        else:
            end_date = datetime.strptime(week_end, "%Y-%m-%d").date()

        if week_start is None:
            start_date = end_date - timedelta(days=7)
        else:
            start_date = datetime.strptime(week_start, "%Y-%m-%d").date()

        # æº–å‚™é›†ç¾¤æ•¸æ“šï¼ˆåŠ å…¥ä»£è¡¨æ€§æ–‡ç« ï¼‰
        clusters_with_articles = []
        for cluster in clusters:
            cluster_data = {
                "cluster_id": cluster["cluster_id"],
                "article_count": cluster["article_count"],
                "average_priority": cluster["average_priority"],
                "keywords": cluster.get("keywords", []),
                "representative_articles": []
            }

            # å–å‰ 3 ç¯‡ä»£è¡¨æ€§æ–‡ç« 
            for article_info in cluster["articles"][:3]:
                article_id = article_info["article_id"]
                # å¾å®Œæ•´æ–‡ç« åˆ—è¡¨ä¸­æ‰¾åˆ°é€™ç¯‡æ–‡ç« 
                full_article = next(
                    (a for a in articles if a["id"] == article_id),
                    None
                )
                if full_article:
                    cluster_data["representative_articles"].append({
                        "title": full_article["title"],
                        "url": full_article["url"],
                        "summary": full_article.get("summary", ""),
                        "priority_score": full_article.get("priority_score", 0.0)
                    })

            clusters_with_articles.append(cluster_data)

        # æº–å‚™ Top æ–‡ç« ï¼ˆå…¨å±€ Top 10ï¼‰
        top_articles = sorted(
            articles,
            key=lambda x: x.get("priority_score", 0.0),
            reverse=True
        )[:10]

        top_articles_data = []
        for article in top_articles:
            top_articles_data.append({
                "title": article["title"],
                "url": article["url"],
                "summary": article.get("summary", ""),
                "priority_score": article.get("priority_score", 0.0),
                "tags": article.get("tags", ""),
                "key_insights": article.get("key_insights", [])
            })

        # çµ„åˆå®Œæ•´è¼¸å…¥
        return {
            "week_start": str(start_date),
            "week_end": str(end_date),
            "total_articles": len(articles),
            "analyzed_articles": len(articles),
            "topic_clusters": clusters_with_articles,
            "hot_trends": trend_result["hot_trends"],
            "emerging_topics": trend_result["emerging_topics"],
            "top_articles_overall": top_articles_data
        }

    def _parse_llm_output(self, response_text: str) -> Optional[Dict[str, Any]]:
        """
        è§£æ LLM è¼¸å‡ºï¼ˆæ”¯æ´ç´” JSON æˆ– Markdown åŒ…è£ï¼‰

        Args:
            response_text: LLM å›æ‡‰æ–‡æœ¬

        Returns:
            dict or None: è§£æå¾Œçš„ JSONï¼Œå¤±æ•—è¿”å› None
        """
        # å˜—è©¦ç›´æ¥è§£æ JSON
        try:
            return json.loads(response_text)
        except json.JSONDecodeError:
            pass

        # å˜—è©¦æå– Markdown åŒ…è£çš„ JSON
        import re
        json_match = re.search(r'```(?:json)?\s*\n(.*?)\n```', response_text, re.DOTALL)
        if json_match:
            try:
                return json.loads(json_match.group(1))
            except json.JSONDecodeError:
                pass

        # è§£æå¤±æ•—
        self.logger.error(f"Failed to parse LLM output: {response_text[:200]}...")
        return None

    def _format_and_send(
        self,
        report_data: Dict[str, Any],
        dry_run: bool
    ) -> Dict[str, Any]:
        """
        æ ¼å¼åŒ–ä¸¦ç™¼é€éƒµä»¶

        Args:
            report_data: LLM ç”Ÿæˆçš„å ±å‘Šæ•¸æ“š
            dry_run: æ˜¯å¦ç‚ºæ¸¬è©¦æ¨¡å¼

        Returns:
            dict: ç™¼é€çµæœ
        """
        # æ ¼å¼åŒ–ï¼ˆä½¿ç”¨ DigestFormatter çš„ weekly æ–¹æ³•ï¼‰
        formatter = DigestFormatter()

        # æš«æ™‚ä½¿ç”¨ Daily æ ¼å¼ï¼ˆå¾ŒçºŒæœƒæ“´å±• Weekly æ ¼å¼ï¼‰
        # TODO: å¯¦ä½œ format_weekly_html() å’Œ format_weekly_text()

        # ç°¡å–®æ ¼å¼åŒ–ï¼ˆè‡¨æ™‚æ–¹æ¡ˆï¼‰
        subject = f"InsightCosmos Weekly Report - {report_data.get('week_start', 'N/A')} to {report_data.get('week_end', 'N/A')}"

        # çµ„ç¹”æ–‡æœ¬å…§å®¹
        text_body = self._format_simple_text(report_data)
        html_body = self._format_simple_html(report_data)

        # ç™¼é€éƒµä»¶
        if not dry_run:
            from src.tools.email_sender import EmailConfig
            email_config = EmailConfig(
                smtp_host=self.config.smtp_host,
                smtp_port=self.config.smtp_port,
                sender_email=self.config.email_account,
                sender_password=self.config.email_password,
                use_tls=self.config.smtp_use_tls
            )
            sender = EmailSender(email_config)
            send_result = sender.send(
                to_email=self.config.email_account,
                subject=subject,
                html_body=html_body,
                text_body=text_body
            )

            if send_result["status"] == "success":
                self.logger.info(f"Email sent to {self.config.email_account}")
            else:
                self.logger.error(f"Email sending failed: {send_result.get('error_message')}")

            return {
                "status": send_result["status"],
                "subject": subject,
                "recipients": [self.config.email_account],
                "html_body": html_body,
                "text_body": text_body,
                "error_message": send_result.get("error_message"),
                "suggestion": send_result.get("suggestion")
            }
        else:
            self.logger.info("DRY RUN: Email not sent")
            return {
                "status": "success",
                "subject": subject,
                "recipients": [self.config.email_account],
                "html_body": html_body,
                "text_body": text_body
            }

    def _format_simple_text(self, report_data: Dict[str, Any]) -> str:
        """ç°¡å–®çš„ç´”æ–‡å­—æ ¼å¼åŒ–ï¼ˆè‡¨æ™‚æ–¹æ¡ˆï¼‰"""
        lines = []
        lines.append("=" * 80)
        lines.append("InsightCosmos Weekly Report")
        lines.append("=" * 80)
        lines.append("")
        lines.append(f"é€±ç¸½çµ: {report_data.get('week_summary', 'N/A')}")
        lines.append("")
        lines.append("=" * 80)
        lines.append("ç†±é–€è¶¨å‹¢")
        lines.append("=" * 80)

        for i, trend in enumerate(report_data.get("hot_trends", []), 1):
            lines.append(f"\n{i}. {trend.get('trend_name', 'N/A')}")
            lines.append(f"   è­‰æ“š: {trend.get('evidence', 'N/A')}")
            lines.append(f"   å»ºè­°: {trend.get('action_suggestion', 'N/A')}")

        lines.append("\n" + "=" * 80)
        lines.append("Top æ–‡ç« ")
        lines.append("=" * 80)

        for i, article in enumerate(report_data.get("top_articles", []), 1):
            lines.append(f"\n{i}. {article.get('title', 'N/A')}")
            lines.append(f"   {article.get('url', 'N/A')}")
            lines.append(f"   è¦é»: {article.get('key_takeaway', 'N/A')}")

        lines.append("\n" + "=" * 80)
        lines.append("Generated by InsightCosmos")
        lines.append("=" * 80)

        return "\n".join(lines)

    def _format_simple_html(self, report_data: Dict[str, Any]) -> str:
        """ç°¡å–®çš„ HTML æ ¼å¼åŒ–ï¼ˆè‡¨æ™‚æ–¹æ¡ˆï¼‰"""
        html = f"""
<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <style>
        body {{ font-family: Arial, sans-serif; line-height: 1.6; max-width: 800px; margin: 0 auto; padding: 20px; }}
        h1 {{ color: #2c3e50; border-bottom: 3px solid #3498db; padding-bottom: 10px; }}
        h2 {{ color: #34495e; margin-top: 30px; }}
        .summary {{ background: #ecf0f1; padding: 15px; border-left: 4px solid #3498db; margin: 20px 0; }}
        .trend {{ background: #fff3cd; padding: 15px; margin: 15px 0; border-radius: 5px; }}
        .article {{ background: #e8f5e9; padding: 15px; margin: 15px 0; border-radius: 5px; }}
        .footer {{ margin-top: 40px; text-align: center; color: #7f8c8d; font-size: 0.9em; }}
    </style>
</head>
<body>
    <h1>InsightCosmos Weekly Report</h1>

    <div class="summary">
        <strong>é€±ç¸½çµ:</strong> {report_data.get('week_summary', 'N/A')}
    </div>

    <h2>ğŸ”¥ ç†±é–€è¶¨å‹¢</h2>
"""

        for i, trend in enumerate(report_data.get("hot_trends", []), 1):
            html += f"""
    <div class="trend">
        <h3>{i}. {trend.get('trend_name', 'N/A')}</h3>
        <p><strong>è­‰æ“š:</strong> {trend.get('evidence', 'N/A')}</p>
        <p><strong>å»ºè­°:</strong> {trend.get('action_suggestion', 'N/A')}</p>
    </div>
"""

        html += "<h2>ğŸ“° Top æ–‡ç« </h2>"

        for i, article in enumerate(report_data.get("top_articles", []), 1):
            html += f"""
    <div class="article">
        <h3>{i}. <a href="{article.get('url', '#')}">{article.get('title', 'N/A')}</a></h3>
        <p><strong>è¦é»:</strong> {article.get('key_takeaway', 'N/A')}</p>
    </div>
"""

        html += """
    <div class="footer">
        <p>Generated by InsightCosmos | Your Personal Intelligence Universe</p>
    </div>
</body>
</html>
"""
        return html


# ============================================================================
# ä¾¿æ·å‡½æ•¸
# ============================================================================

def generate_weekly_report(
    config: Optional[Config] = None,
    week_start: Optional[str] = None,
    week_end: Optional[str] = None,
    dry_run: bool = False
) -> Dict[str, Any]:
    """
    ä¾¿æ·å‡½æ•¸ï¼šç”Ÿæˆé€±å ±

    Args:
        config: é…ç½®å°è±¡ï¼ˆé»˜èªå¾ç’°å¢ƒè®Šæ•¸è¼‰å…¥ï¼‰
        week_start: é€±é–‹å§‹æ—¥æœŸï¼ˆé»˜èª 7 å¤©å‰ï¼‰
        week_end: é€±çµæŸæ—¥æœŸï¼ˆé»˜èªä»Šå¤©ï¼‰
        dry_run: æ˜¯å¦ç‚ºæ¸¬è©¦æ¨¡å¼

    Returns:
        dict: ç”Ÿæˆçµæœ

    Example:
        >>> from src.agents.curator_weekly import generate_weekly_report
        >>> result = generate_weekly_report(dry_run=True)
        >>> print(result["subject"])
        InsightCosmos Weekly Report - 2025-11-18 to 2025-11-24
    """
    if config is None:
        config = Config.from_env()

    runner = CuratorWeeklyRunner(config)
    return runner.generate_weekly_report(week_start, week_end, dry_run)
