#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
InsightCosmos ç”Ÿç”¢æ¨¡å¼åŸ·è¡Œè…³æœ¬ï¼ˆå«è©³ç´°æ—¥èªŒè¨˜éŒ„ï¼‰

æ­¤è…³æœ¬æœƒï¼š
1. åŸ·è¡Œå®Œæ•´çš„æ¯æ—¥æƒ…å ±æ”¶é›†æµç¨‹
2. è¨˜éŒ„è©³ç´°çš„è³‡æ–™ä¾†æºè³‡è¨Š
3. ç”ŸæˆåŸ·è¡Œå ±å‘Šä¸¦ä¿å­˜åˆ° docs/optimization/
"""

import sys
import json
from datetime import datetime
from pathlib import Path

# ç¢ºä¿å¯ä»¥å°å…¥å°ˆæ¡ˆæ¨¡çµ„
project_root = Path(__file__).parent
if str(project_root) not in sys.path:
    sys.path.insert(0, str(project_root))

from src.utils.config import Config
from src.orchestrator.daily_runner import DailyPipelineOrchestrator


def main():
    """ä¸»åŸ·è¡Œå‡½æ•¸"""

    # åˆå§‹åŒ–
    print("=" * 80)
    print("InsightCosmos - æ¯æ—¥æƒ…å ±æ”¶é›†èˆ‡åˆ†æ (ç”Ÿç”¢æ¨¡å¼)")
    print("=" * 80)
    print()

    # è¼‰å…¥é…ç½®
    print("ğŸ“‹ è¼‰å…¥é…ç½®...")
    try:
        config = Config.from_env()
        print(f"âœ“ é…ç½®è¼‰å…¥æˆåŠŸ")
        print(f"  ä½¿ç”¨è€…: {config.user_name}")
        print(f"  èˆˆè¶£é ˜åŸŸ: {config.user_interests}")
        print()
    except Exception as e:
        print(f"âœ— é…ç½®è¼‰å…¥å¤±æ•—: {e}")
        sys.exit(1)

    # é¡¯ç¤ºè³‡æ–™ä¾†æºè³‡è¨Š
    print("ğŸ“¡ è³‡æ–™ä¾†æºé…ç½®:")
    print()
    print("  ã€RSS Feedsã€‘")
    rss_feeds = [
        "https://techcrunch.com/category/artificial-intelligence/feed/",
        "https://venturebeat.com/category/ai/feed/",
        "https://spectrum.ieee.org/feeds/topic/robotics.rss",
        "https://www.therobotreport.com/feed/"
    ]
    for idx, feed in enumerate(rss_feeds, 1):
        print(f"    {idx}. {feed}")
    print(f"    â†’ æ¯å€‹ Feed æ”¶é›†: 5 ç¯‡æ–‡ç« ")
    print()

    print("  ã€Google Search Groundingã€‘")
    interests = config.get_interests_list()
    print(f"    åŸºæ–¼ä½¿ç”¨è€…èˆˆè¶£ç”Ÿæˆæœå°‹æŸ¥è©¢: {', '.join(interests)}")
    print(f"    â†’ æ¯å€‹æŸ¥è©¢æ”¶é›†: 5 ç¯‡æ–‡ç« ")
    print()

    print("=" * 80)
    print()

    # è¨˜éŒ„é–‹å§‹æ™‚é–“
    start_time = datetime.now()
    timestamp = start_time.strftime("%Y%m%d_%H%M%S")

    # åŸ·è¡Œ Pipeline
    print("ğŸš€ é–‹å§‹åŸ·è¡Œ Daily Pipeline...")
    print()

    try:
        orchestrator = DailyPipelineOrchestrator(config)
        result = orchestrator.run(dry_run=False)

        # è¨˜éŒ„çµæŸæ™‚é–“
        end_time = datetime.now()
        duration = (end_time - start_time).total_seconds()

        # é¡¯ç¤ºåŸ·è¡Œçµæœ
        print()
        print("=" * 80)
        print("åŸ·è¡Œçµæœæ‘˜è¦")
        print("=" * 80)

        if result["success"]:
            print("âœ“ Pipeline åŸ·è¡ŒæˆåŠŸ")
        else:
            print("âœ— Pipeline åŸ·è¡Œå¤±æ•—æˆ–éƒ¨åˆ†å¤±æ•—")

        print()
        print(f"åŸ·è¡Œæ™‚é–“: {duration:.1f} ç§’")
        print(f"æ”¶é›†æ–‡ç« æ•¸: {result['stats']['phase1_collected']}")
        print(f"æ–°å­˜å„²æ–‡ç« æ•¸: {result['stats']['phase1_stored']}")
        print(f"åˆ†ææ–‡ç« æ•¸: {result['stats']['phase2_analyzed']}")
        print(f"éƒµä»¶ç™¼é€: {'âœ“' if result['stats']['phase3_sent'] else 'âœ—'}")

        if result['errors']:
            print(f"\néŒ¯èª¤æ•¸é‡: {len(result['errors'])}")
            for error in result['errors']:
                print(f"  - {error['phase']}: {error['error_message']}")

        print()
        print("=" * 80)

        # ç”Ÿæˆè©³ç´°å ±å‘Š
        report = generate_report(
            config=config,
            result=result,
            start_time=start_time,
            end_time=end_time,
            rss_feeds=rss_feeds
        )

        # ä¿å­˜å ±å‘Š
        report_dir = Path("docs/optimization")
        report_dir.mkdir(parents=True, exist_ok=True)

        report_file = report_dir / f"production_run_{timestamp}.md"
        with open(report_file, "w", encoding="utf-8") as f:
            f.write(report)

        print(f"\nğŸ“„ åŸ·è¡Œå ±å‘Šå·²ä¿å­˜: {report_file}")

        # ä¿å­˜ JSON æ ¼å¼çš„è©³ç´°æ•¸æ“š
        json_file = report_dir / f"production_run_{timestamp}.json"
        with open(json_file, "w", encoding="utf-8") as f:
            json.dump({
                "execution_info": {
                    "start_time": start_time.isoformat(),
                    "end_time": end_time.isoformat(),
                    "duration_seconds": duration
                },
                "config": {
                    "user_name": config.user_name,
                    "user_interests": config.user_interests,
                    "interests_list": config.get_interests_list()
                },
                "data_sources": {
                    "rss_feeds": rss_feeds,
                    "rss_articles_per_feed": 5,
                    "google_search_queries": f"Generated based on: {config.user_interests}",
                    "google_search_results_per_query": 5
                },
                "result": result
            }, f, indent=2, ensure_ascii=False)

        print(f"ğŸ“Š è©³ç´°æ•¸æ“šå·²ä¿å­˜: {json_file}")
        print()

        # é€€å‡ºç¢¼
        sys.exit(0 if result["success"] else 1)

    except KeyboardInterrupt:
        print("\n\nâš ï¸  åŸ·è¡Œè¢«ä½¿ç”¨è€…ä¸­æ–·")
        sys.exit(130)

    except Exception as e:
        print(f"\n\nâŒ åŸ·è¡Œå¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


def generate_report(config, result, start_time, end_time, rss_feeds):
    """ç”Ÿæˆ Markdown æ ¼å¼çš„åŸ·è¡Œå ±å‘Š"""

    duration = (end_time - start_time).total_seconds()

    report = f"""# InsightCosmos æ¯æ—¥æƒ…å ±æ”¶é›†åŸ·è¡Œå ±å‘Š

**åŸ·è¡Œæ™‚é–“**: {start_time.strftime("%Y-%m-%d %H:%M:%S")} ~ {end_time.strftime("%H:%M:%S")}
**åŸ·è¡Œæ™‚é•·**: {duration:.1f} ç§’
**åŸ·è¡Œæ¨¡å¼**: ç”Ÿç”¢æ¨¡å¼ (Production)
**åŸ·è¡Œç‹€æ…‹**: {'âœ… æˆåŠŸ' if result['success'] else 'âŒ å¤±æ•—'}

---

## ğŸ“¡ è³‡æ–™ä¾†æºé…ç½®

### RSS Feeds

æœ¬æ¬¡åŸ·è¡Œå¾ä»¥ä¸‹ RSS ä¾†æºæ”¶é›†æ–‡ç« ï¼š

"""

    for idx, feed in enumerate(rss_feeds, 1):
        # æå–ç¶²ç«™åç¨±
        if "techcrunch.com" in feed:
            source_name = "TechCrunch AI"
        elif "venturebeat.com" in feed:
            source_name = "VentureBeat AI"
        elif "spectrum.ieee.org" in feed:
            source_name = "IEEE Spectrum Robotics"
        elif "therobotreport.com" in feed:
            source_name = "The Robot Report"
        else:
            source_name = "Unknown"

        report += f"{idx}. **{source_name}**\n"
        report += f"   - URL: `{feed}`\n"
        report += f"   - æ¯æ¬¡æ”¶é›†: 5 ç¯‡æ–‡ç« \n\n"

    report += f"""
**RSS ç¸½è¨ˆ**: {len(rss_feeds)} å€‹ä¾†æºï¼Œé æœŸæ”¶é›†æœ€å¤š {len(rss_feeds) * 5} ç¯‡æ–‡ç« 

### Google Search Grounding

åŸºæ–¼ä½¿ç”¨è€…èˆˆè¶£è‡ªå‹•ç”Ÿæˆæœå°‹æŸ¥è©¢ï¼š

**ä½¿ç”¨è€…èˆˆè¶£**: {config.user_interests}

Scout Agent æœƒæ ¹æ“šä»¥ä¸‹èˆˆè¶£é ˜åŸŸç”Ÿæˆæœå°‹æŸ¥è©¢ï¼š
"""

    interests = config.get_interests_list()
    for interest in interests:
        report += f"- **{interest}**: ç”Ÿæˆç›¸é—œçš„æœ€æ–°è³‡è¨Šæœå°‹æŸ¥è©¢\n"

    report += f"""
**æœå°‹ç­–ç•¥**:
- æ¯å€‹èˆˆè¶£é ˜åŸŸè‡³å°‘ç”Ÿæˆ 1 å€‹æœå°‹æŸ¥è©¢
- æ¯å€‹æŸ¥è©¢æ”¶é›†æœ€å¤š 5 ç¯‡æ–‡ç« 
- ä½¿ç”¨ Google Search Grounding API (é€é Gemini API)

---

## ğŸ“Š åŸ·è¡Œçµæœçµ±è¨ˆ

### Phase 1: Scout Agent (è³‡æ–™æ”¶é›†)

| æŒ‡æ¨™ | æ•¸å€¼ |
|------|------|
| æ”¶é›†æ–‡ç« ç¸½æ•¸ | {result['stats']['phase1_collected']} |
| æ–°å­˜å„²æ–‡ç« æ•¸ | {result['stats']['phase1_stored']} |
| é‡è¤‡æ–‡ç« æ•¸ | {result['stats']['phase1_collected'] - result['stats']['phase1_stored']} |

### Phase 2: Analyst Agent (å…§å®¹åˆ†æ)

| æŒ‡æ¨™ | æ•¸å€¼ |
|------|------|
| åˆ†ææ–‡ç« æ•¸ | {result['stats']['phase2_analyzed']} |
| åˆ†ææˆåŠŸç‡ | {(result['stats']['phase2_analyzed'] / result['stats']['phase1_stored'] * 100) if result['stats']['phase1_stored'] > 0 else 0:.1f}% |

### Phase 3: Curator Agent (å ±å‘Šç”Ÿæˆèˆ‡ç™¼é€)

| æŒ‡æ¨™ | æ•¸å€¼ |
|------|------|
| éƒµä»¶ç™¼é€ç‹€æ…‹ | {'âœ… æˆåŠŸ' if result['stats']['phase3_sent'] else 'âŒ å¤±æ•—'} |
| æ”¶ä»¶äºº | {config.email_account} |

---

## âš ï¸ éŒ¯èª¤èˆ‡è­¦å‘Š

"""

    if result['errors']:
        report += f"**éŒ¯èª¤æ•¸é‡**: {len(result['errors'])}\n\n"
        for idx, error in enumerate(result['errors'], 1):
            report += f"### éŒ¯èª¤ {idx}\n\n"
            report += f"- **éšæ®µ**: {error['phase']}\n"
            report += f"- **é¡å‹**: {error['error_type']}\n"
            report += f"- **è¨Šæ¯**: {error['error_message']}\n"
            report += f"- **æ™‚é–“**: {error['timestamp']}\n\n"
    else:
        report += "**ç„¡éŒ¯èª¤** âœ…\n\n"

    report += f"""
---

## ğŸ¯ è³‡æ–™æµç¨‹èªªæ˜

### å®Œæ•´ Pipeline æµç¨‹

```
1. Scout Agent (è³‡æ–™æ”¶é›†)
   â”œâ”€ RSS Fetcher
   â”‚  â””â”€ å¾ {len(rss_feeds)} å€‹ RSS ä¾†æºæ”¶é›†æ–‡ç« 
   â”‚
   â””â”€ Google Search Grounding
      â””â”€ åŸºæ–¼ {len(interests)} å€‹èˆˆè¶£é ˜åŸŸç”ŸæˆæŸ¥è©¢ä¸¦æœå°‹

2. Analyst Agent (å…§å®¹åˆ†æ)
   â”œâ”€ Content Extraction: æå–å®Œæ•´æ–‡ç« å…§å®¹
   â”œâ”€ LLM Analysis: ä½¿ç”¨ Gemini 2.5 Flash åˆ†æ
   â””â”€ Embedding: ç”Ÿæˆå‘é‡åµŒå…¥ä¸¦å­˜å„²

3. Curator Agent (å ±å‘Šç”Ÿæˆ)
   â”œâ”€ Digest Formatting: ç”Ÿæˆæ¯æ—¥æ‘˜è¦
   â””â”€ Email Delivery: é€é SMTP ç™¼é€å ±å‘Š
```

### è³‡æ–™å»é‡æ©Ÿåˆ¶

ç³»çµ±åœ¨ä»¥ä¸‹éšæ®µåŸ·è¡Œå»é‡ï¼š

1. **Scout Agent å…§éƒ¨**: åŸºæ–¼ URL å»é‡
2. **ArticleStore å­˜å„²**: æª¢æŸ¥ URL æ˜¯å¦å·²å­˜åœ¨æ–¼è³‡æ–™åº«
3. **æœ€çµ‚è¼¸å‡º**: ç¢ºä¿ä¸æœƒåˆ†ææˆ–ç™¼é€é‡è¤‡å…§å®¹

---

## ğŸ“ å‚™è¨»

- æœ¬å ±å‘Šç”± `run_production_with_log.py` è‡ªå‹•ç”Ÿæˆ
- è©³ç´°æ—¥èªŒè«‹æŸ¥çœ‹ç³»çµ±æ—¥èªŒè¼¸å‡º
- JSON æ ¼å¼çš„åŸå§‹æ•¸æ“šå·²åŒæ™‚ä¿å­˜

**ç”Ÿæˆæ™‚é–“**: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}
"""

    return report


if __name__ == "__main__":
    main()
